<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=PingFang SC:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhangruochi.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Build and Evaluate a Linear Risk model Welcome to the first assignment in Course 2! Outline  1. Import Packages 2. Load Data 3. Explore the Dataset 4. Mean-Normalize the Data  Exercise 1  5. Build the">
<meta property="og:type" content="article">
<meta property="og:title" content="Build and Evaluate a Linear Risk model">
<meta property="og:url" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/index.html">
<meta property="og:site_name" content="RUOCHI.AI">
<meta property="og:description" content="Build and Evaluate a Linear Risk model Welcome to the first assignment in Course 2! Outline  1. Import Packages 2. Load Data 3. Explore the Dataset 4. Mean-Normalize the Data  Exercise 1  5. Build the">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_18_0.png">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_18_1.png">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_18_2.png">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_18_3.png">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_20_0.png">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_22_0.png">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_22_1.png">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_22_2.png">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_22_3.png">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_35_0.png">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_35_1.png">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_35_2.png">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_35_3.png">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_56_0.png">
<meta property="og:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_71_0.png">
<meta property="article:published_time" content="2020-04-18T15:50:08.000Z">
<meta property="article:modified_time" content="2020-04-19T15:09:57.000Z">
<meta property="article:author" content="Ruochi Zhang">
<meta property="article:tag" content="Medicine">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/output_18_0.png">

<link rel="canonical" href="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Build and Evaluate a Linear Risk model | RUOCHI.AI</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RUOCHI.AI</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Build and Evaluate a Linear Risk model
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-18 23:50:08" itemprop="dateCreated datePublished" datetime="2020-04-18T23:50:08+08:00">2020-04-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-19 23:09:57" itemprop="dateModified" datetime="2020-04-19T23:09:57+08:00">2020-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="build-and-evaluate-a-linear-risk-model">Build and Evaluate a Linear Risk model</h1>
<p>Welcome to the first assignment in Course 2!</p>
<h2 id="outline">Outline</h2>
<ul>
<li><a href="#1">1. Import Packages</a></li>
<li><a href="#2">2. Load Data</a></li>
<li><a href="#3">3. Explore the Dataset</a></li>
<li><a href="#4">4. Mean-Normalize the Data</a>
<ul>
<li><a href="#Ex-1">Exercise 1</a></li>
</ul></li>
<li><a href="#Ex-2">5. Build the Model</a>
<ul>
<li><a href="#Ex-2">Exercise 2</a></li>
</ul></li>
<li><a href="#6">6. Evaluate the Model Using the C-Index</a>
<ul>
<li><a href="#Ex-3">Exercise 3</a></li>
</ul></li>
<li><a href="#7">7. Evaluate the Model on the Test Set</a></li>
<li><a href="#8">8. Improve the Model</a>
<ul>
<li><a href="#Ex-4">Exercise 4</a></li>
</ul></li>
<li><a href="#9">9. Evalute the Improved Model</a></li>
</ul>
<h2 id="overview-of-the-assignment">Overview of the Assignment</h2>
<p>In this assignment, you'll build a risk score model for retinopathy in diabetes patients using logistic regression.</p>
<p>As we develop the model, we will learn about the following topics:</p>
<ul>
<li>Data preprocessing
<ul>
<li>Log transformations</li>
<li>Standardization</li>
</ul></li>
<li>Basic Risk Models
<ul>
<li>Logistic Regression</li>
<li>C-index</li>
<li>Interactions Terms</li>
</ul></li>
</ul>
<h3 id="diabetic-retinopathy">Diabetic Retinopathy</h3>
<p>Retinopathy is an eye condition that causes changes to the blood vessels in the part of the eye called the retina. This often leads to vision changes or blindness. Diabetic patients are known to be at high risk for retinopathy.</p>
<h3 id="logistic-regression">Logistic Regression</h3>
<p>Logistic regression is an appropriate analysis to use for predicting the probability of a binary outcome. In our case, this would be the probability of having or not having diabetic retinopathy. Logistic Regression is one of the most commonly used algorithms for binary classification. It is used to find the best fitting model to describe the relationship between a set of features (also referred to as input, independent, predictor, or explanatory variables) and a binary outcome label (also referred to as an output, dependent, or response variable). Logistic regression has the property that the output prediction is always in the range <span class="math inline">\([0,1]\)</span>. Sometimes this output is used to represent a probability from 0%-100%, but for straight binary classification, the output is converted to either <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span> depending on whether it is below or above a certain threshold, usually <span class="math inline">\(0.5\)</span>.</p>
<p>It may be confusing that the term regression appears in the name even though logistic regression is actually a classification algorithm, but that's just a name it was given for historical reasons.</p>
<p><a name='1'></a> ## 1. Import Packages</p>
<p>We'll first import all the packages that we need for this assignment.</p>
<ul>
<li><code>numpy</code> is the fundamental package for scientific computing in python.</li>
<li><code>pandas</code> is what we'll use to manipulate our data.</li>
<li><code>matplotlib</code> is a plotting library.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure>
<p><a name='2'></a> ## 2. Load Data</p>
<p>First we will load in the dataset that we will use for training and testing our model.</p>
<ul>
<li>Run the next cell to load the data using a function imported from our local utils module.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> load_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># This function creates randomly generated data</span></span><br><span class="line"><span class="comment"># X, y = load_data(6000)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># For stability, load data from files that were generated using the load_data</span></span><br><span class="line">X = pd.read_csv(<span class="string">&#x27;X_data.csv&#x27;</span>,index_col=<span class="number">0</span>)</span><br><span class="line">y_df = pd.read_csv(<span class="string">&#x27;y_data.csv&#x27;</span>,index_col=<span class="number">0</span>)</span><br><span class="line">y = y_df[<span class="string">&#x27;y&#x27;</span>]</span><br></pre></td></tr></table></figure>
<p><code>X</code> and <code>y</code> are Pandas DataFrames that hold the data for 6,000 diabetic patients.</p>
<p><a name='3'></a> ## 3. Explore the Dataset</p>
<p>The features (<code>X</code>) include the following fields: * Age: (years) * Systolic_BP: Systolic blood pressure (mmHg) * Diastolic_BP: Diastolic blood pressure (mmHg) * Cholesterol: (mg/DL)</p>
<p>We can use the <code>head()</code> method to display the first few records of each.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.head()</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
Age
</th>
<th>
Systolic_BP
</th>
<th>
Diastolic_BP
</th>
<th>
Cholesterol
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
77.196340
</td>
<td>
85.288742
</td>
<td>
80.021878
</td>
<td>
79.957109
</td>
</tr>
<tr>
<th>
1
</th>
<td>
63.529850
</td>
<td>
99.379736
</td>
<td>
84.852361
</td>
<td>
110.382411
</td>
</tr>
<tr>
<th>
2
</th>
<td>
69.003986
</td>
<td>
111.349455
</td>
<td>
109.850616
</td>
<td>
100.828246
</td>
</tr>
<tr>
<th>
3
</th>
<td>
82.638210
</td>
<td>
95.056128
</td>
<td>
79.666851
</td>
<td>
87.066303
</td>
</tr>
<tr>
<th>
4
</th>
<td>
78.346286
</td>
<td>
109.154591
</td>
<td>
90.713220
</td>
<td>
92.511770
</td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.shape</span><br></pre></td></tr></table></figure>
<pre><code>(6000, 4)</code></pre>
<p>The target (<code>y</code>) is an indicator of whether or not the patient developed retinopathy.</p>
<ul>
<li>y = 1 : patient has retinopathy.</li>
<li>y = 0 : patient does not have retinopathy.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y.head()</span><br></pre></td></tr></table></figure>
<pre><code>0    1.0
1    1.0
2    1.0
3    1.0
4    1.0
Name: y, dtype: float64</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y.shape</span><br></pre></td></tr></table></figure>
<pre><code>(6000,)</code></pre>
<p>Before we build a model, let's take a closer look at the distribution of our training data. To do this, we will split the data into train and test sets using a 75/25 split.</p>
<p>For this, we can use the built in function provided by sklearn library. See the documentation for <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">sklearn.model_selection.train_test_split</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=<span class="number">0.75</span>, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p>Plot the histograms of each column of <code>X_train</code> below:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> X.columns:</span><br><span class="line">    X_train_raw.loc[:, col].hist()</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_18_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_18_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_18_2.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_18_3.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>As we can see, the distributions have a generally bell shaped distribution, but with slight rightward skew.</p>
<p>Many statistical models assume that the data is normally distributed, forming a symmetric Gaussian bell shape (with no skew) more like the example below.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line">data = np.random.normal(<span class="number">50</span>,<span class="number">12</span>, <span class="number">5000</span>)</span><br><span class="line">fitting_params = norm.fit(data)</span><br><span class="line">norm_dist_fitted = norm(*fitting_params)</span><br><span class="line">t = np.linspace(<span class="number">0</span>,<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line">plt.hist(data, bins=<span class="number">60</span>, density=<span class="literal">True</span>)</span><br><span class="line">plt.plot(t, norm_dist_fitted.pdf(t))</span><br><span class="line">plt.title(<span class="string">&#x27;Example of Normally Distributed Data&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_20_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>We can transform our data to be closer to a normal distribution by removing the skew. One way to remove the skew is by applying the log function to the data.</p>
<p>Let's plot the log of the feature variables to see that it produces the desired effect.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> X_train_raw.columns:</span><br><span class="line">    np.log(X_train_raw.loc[:, col]).hist()</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_22_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_22_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_22_2.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_22_3.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>We can see that the data is more symmetric after taking the log.</p>
<p><a name='4'></a> ## 4. Mean-Normalize the Data</p>
<p>Let's now transform our data so that the distributions are closer to standard normal distributions.</p>
<p>First we will remove some of the skew from the distribution by using the log transformation. Then we will "standardize" the distribution so that it has a mean of zero and standard deviation of 1. Recall that a standard normal distribution has mean of zero and standard deviation of 1.</p>
<p><a name='Ex-1'></a> ### Exercise 1 * Write a function that first removes some of the skew in the data, and then standardizes the distribution so that for each data point <span class="math inline">\(x\)</span>, <span class="math display">\[\overline{x} = \frac{x - mean(x)}{std(x)}\]</span> * Keep in mind that we want to pretend that the test data is "unseen" data. * This implies that it is unavailable to us for the purpose of preparing our data, and so we do not want to consider it when evaluating the mean and standard deviation that we use in the above equation. Instead we want to calculate these values using the training data alone, but then use them for standardizing both the training and the test data. * For a further discussion on the topic, see this article <a target="_blank" rel="noopener" href="https://sebastianraschka.com/faq/docs/scale-training-test.html">"Why do we need to re-use training parameters to transform test data"</a>.</p>
<h4 id="note">Note</h4>
<ul>
<li>For the sample standard deviation, please calculate the unbiased estimator: <span class="math display">\[s = \sqrt{\frac{\sum_{i=1}^n(x_{i} - \bar{x})^2}{n-1}}\]</span></li>
<li>In other words, if you numpy, set the degrees of freedom <code>ddof</code> to 1.</li>
<li>For pandas, the default <code>ddof</code> is already set to 1.</li>
</ul>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
When working with Pandas DataFrames, you can use the aggregation functions <code>mean</code> and <code>std</code> functions. Note that in order to apply an aggregation function separately for each row or each column, you'll set the axis parameter to either <code>0</code> or <code>1</code>. One produces the aggregation along columns and the other along rows, but it is easy to get them confused. So experiment with each option below to see which one you should use to get an average for each column in the dataframe. <code> avg = df.mean(axis=0) avg = df.mean(axis=1) </code>
</li>
<br></br>
<li>
Remember to use <b>training</b> data statistics when standardizing both the training and the test data.
</li>
</ul>
</p>
</details>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_standard_normal</span>(<span class="params">df_train, df_test</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    In order to make the data closer to a normal distribution, take log</span></span><br><span class="line"><span class="string">    transforms to reduce the skew.</span></span><br><span class="line"><span class="string">    Then standardize the distribution with a mean of zero and standard deviation of 1. </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      df_train (dataframe): unnormalized training data.</span></span><br><span class="line"><span class="string">      df_test (dataframe): unnormalized test data.</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      df_train_normalized (dateframe): normalized training data.</span></span><br><span class="line"><span class="string">      df_test_normalized (dataframe): normalized test data.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###  </span></span><br><span class="line">    <span class="comment"># Remove skew by applying the log function to the train set, and to the test set</span></span><br><span class="line">    df_train_unskewed = np.log(df_train)</span><br><span class="line">    df_test_unskewed = np.log(df_test)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#calculate the mean and standard deviation of the training set</span></span><br><span class="line">    mean = df_train_unskewed.mean(axis = <span class="number">0</span>)</span><br><span class="line">    stdev = df_train_unskewed.std(axis = <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># standardize the training set</span></span><br><span class="line">    df_train_standardized = (df_train_unskewed - mean)/ stdev</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># standardize the test set (see instructions and hints above)</span></span><br><span class="line">    df_test_standardized = (df_test_unskewed - mean) / stdev</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> df_train_standardized, df_test_standardized</span><br></pre></td></tr></table></figure>
<h4 id="test-your-work">Test Your Work</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test</span></span><br><span class="line">tmp_train = pd.DataFrame(&#123;<span class="string">&#x27;field1&#x27;</span>: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">10</span>], <span class="string">&#x27;field2&#x27;</span>: [<span class="number">4</span>,<span class="number">5</span>,<span class="number">11</span>]&#125;)</span><br><span class="line">tmp_test = pd.DataFrame(&#123;<span class="string">&#x27;field1&#x27;</span>: [<span class="number">1</span>,<span class="number">3</span>,<span class="number">10</span>], <span class="string">&#x27;field2&#x27;</span>: [<span class="number">4</span>,<span class="number">6</span>,<span class="number">11</span>]&#125;)</span><br><span class="line">tmp_train_transformed, tmp_test_transformed = make_standard_normal(tmp_train,tmp_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Training set transformed field1 has mean <span class="subst">&#123;tmp_train_transformed[<span class="string">&#x27;field1&#x27;</span>].mean(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span> and standard deviation <span class="subst">&#123;tmp_train_transformed[<span class="string">&#x27;field1&#x27;</span>].std(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span> &quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Test set transformed, field1 has mean <span class="subst">&#123;tmp_test_transformed[<span class="string">&#x27;field1&#x27;</span>].mean(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span> and standard deviation <span class="subst">&#123;tmp_test_transformed[<span class="string">&#x27;field1&#x27;</span>].std(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Skew of training set field1 before transformation: <span class="subst">&#123;tmp_train[<span class="string">&#x27;field1&#x27;</span>].skew(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Skew of training set field1 after transformation: <span class="subst">&#123;tmp_train_transformed[<span class="string">&#x27;field1&#x27;</span>].skew(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Skew of test set field1 before transformation: <span class="subst">&#123;tmp_test[<span class="string">&#x27;field1&#x27;</span>].skew(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Skew of test set field1 after transformation: <span class="subst">&#123;tmp_test_transformed[<span class="string">&#x27;field1&#x27;</span>].skew(axis=<span class="number">0</span>):<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Training set transformed field1 has mean -0.0000 and standard deviation 1.0000 
Test set transformed, field1 has mean 0.1144 and standard deviation 0.9749
Skew of training set field1 before transformation: 1.6523
Skew of training set field1 after transformation: 1.0857
Skew of test set field1 before transformation: 1.3896
Skew of test set field1 after transformation: 0.1371</code></pre>
<h4 id="expected-output">Expected Output:</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Training set transformed field1 has mean <span class="number">-0.0000</span> <span class="keyword">and</span> standard deviation <span class="number">1.0000</span> </span><br><span class="line">Test set transformed, field1 has mean <span class="number">0.1144</span> <span class="keyword">and</span> standard deviation <span class="number">0.9749</span></span><br><span class="line">Skew of training set field1 before transformation: <span class="number">1.6523</span></span><br><span class="line">Skew of training set field1 after transformation: <span class="number">1.0857</span></span><br><span class="line">Skew of test set field1 before transformation: <span class="number">1.3896</span></span><br><span class="line">Skew of test set field1 after transformation: <span class="number">0.1371</span></span><br></pre></td></tr></table></figure>
<h4 id="transform-training-and-test-data">Transform training and test data</h4>
<p>Use the function that you just implemented to make the data distribution closer to a standard normal distribution.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, X_test = make_standard_normal(X_train_raw, X_test_raw)</span><br></pre></td></tr></table></figure>
<p>After transforming the training and test sets, we'll expect the training set to be centered at zero with a standard deviation of <span class="math inline">\(1\)</span>.</p>
<p>We will avoid observing the test set during model training in order to avoid biasing the model training process, but let's have a look at the distributions of the transformed training data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> X_train.columns:</span><br><span class="line">    X_train[col].hist()</span><br><span class="line">    plt.title(col)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_35_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_35_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_35_2.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<figure>
<img src="output_35_3.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p><a name='5'></a> ## 5. Build the Model</p>
<p>Now we are ready to build the risk model by training logistic regression with our data.</p>
<p><a name='Ex-2'></a> ### Exercise 2</p>
<ul>
<li>Implement the <code>lr_model</code> function to build a model using logistic regression with the <code>LogisticRegression</code> class from <code>sklearn</code>.</li>
<li>See the documentation for <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit">sklearn.linear_model.LogisticRegression</a>.</li>
</ul>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
You can leave all the parameters to their default values when constructing an instance of the <code>sklearn.linear_model.LogisticRegression</code> class. If you get a warning message regarding the <code>solver</code> parameter, however, you may want to specify that particular one explicitly with <code>solver='lbfgs'</code>.
</li>
<br></br>
</ul>
</p>
</details>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lr_model</span>(<span class="params">X_train, y_train</span>):</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    <span class="comment"># import the LogisticRegression class</span></span><br><span class="line">    <span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># create the model object</span></span><br><span class="line">    model = LogisticRegression(solver=<span class="string">&#x27;lbfgs&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># fit the model to the training data</span></span><br><span class="line">    model.fit(X_train, y_train)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="comment">#return the fitted model</span></span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<h4 id="test-your-work-1">Test Your Work</h4>
<p>Note: the <code>predict</code> method returns the model prediction <em>after</em> converting it from a value in the <span class="math inline">\([0,1]\)</span> range to a <span class="math inline">\(0\)</span> or <span class="math inline">\(1\)</span> depending on whether it is below or above <span class="math inline">\(0.5\)</span>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test</span></span><br><span class="line">tmp_model = lr_model(X_train[<span class="number">0</span>:<span class="number">3</span>], y_train[<span class="number">0</span>:<span class="number">3</span>] )</span><br><span class="line"><span class="built_in">print</span>(tmp_model.predict(X_train[<span class="number">4</span>:<span class="number">5</span>]))</span><br><span class="line"><span class="built_in">print</span>(tmp_model.predict(X_train[<span class="number">5</span>:<span class="number">6</span>]))</span><br></pre></td></tr></table></figure>
<pre><code>[1.]
[1.]</code></pre>
<h4 id="expected-output-1">Expected Output:</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">1.</span>]</span><br><span class="line">[<span class="number">0.</span>]</span><br></pre></td></tr></table></figure>
<p>Now that we've tested our model, we can go ahead and build it. Note that the <code>lr_model</code> function also fits the model to the training data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_X = lr_model(X_train, y_train)</span><br></pre></td></tr></table></figure>
<p><a name='6'></a> ## 6. Evaluate the Model Using the C-index</p>
<p>Now that we have a model, we need to evaluate it. We'll do this using the c-index. * The c-index measures the discriminatory power of a risk score. * Intuitively, a higher c-index indicates that the model's prediction is in agreement with the actual outcomes of a pair of patients. * The formula for the c-index is</p>
<p><span class="math display">\[ \mbox{cindex} = \frac{\mbox{concordant} + 0.5 \times \mbox{ties}}{\mbox{permissible}} \]</span></p>
<ul>
<li>A permissible pair is a pair of patients who have different outcomes.</li>
<li>A concordant pair is a permissible pair in which the patient with the higher risk score also has the worse outcome.</li>
<li>A tie is a permissible pair where the patients have the same risk score.</li>
</ul>
<p><a name='Ex-3'></a> ### Exercise 3</p>
<ul>
<li>Implement the <code>cindex</code> function to compute c-index.</li>
<li><code>y_true</code> is the array of actual patient outcomes, 0 if the patient does not eventually get the disease, and 1 if the patient eventually gets the disease.</li>
<li><code>scores</code> is the risk score of each patient. These provide relative measures of risk, so they can be any real numbers. By convention, they are always non-negative.</li>
<li>Here is an example of input data and how to interpret it: <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_true = [<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">scores = [<span class="number">0.45</span>, <span class="number">1.25</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>There are two patients. Index 0 of each array is associated with patient 0. Index 1 is associated with patient 1.</li>
<li>Patient 0 does not have the disease in the future (<code>y_true</code> is 0), and based on past information, has a risk score of 0.45.</li>
<li>Patient 1 has the disease at some point in the future (<code>y_true</code> is 1), and based on past information, has a risk score of 1.25.</li>
</ul></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cindex</span>(<span class="params">y_true, scores</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Input:</span></span><br><span class="line"><span class="string">    y_true (np.array): a 1-D array of true binary outcomes (values of zero or one)</span></span><br><span class="line"><span class="string">        0: patient does not get the disease</span></span><br><span class="line"><span class="string">        1: patient does get the disease</span></span><br><span class="line"><span class="string">    scores (np.array): a 1-D array of corresponding risk scores output by the model</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Output:</span></span><br><span class="line"><span class="string">    c_index (float): (concordant pairs + 0.5*ties) / number of permissible pairs</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    n = <span class="built_in">len</span>(y_true)</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(scores) == n</span><br><span class="line"></span><br><span class="line">    concordant = <span class="number">0</span></span><br><span class="line">    permissible = <span class="number">0</span></span><br><span class="line">    ties = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    <span class="comment"># use two nested for loops to go through all unique pairs of patients</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, n): <span class="comment">#choose the range of j so that j&gt;i</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Check if the pair is permissible (the patient outcomes are different)</span></span><br><span class="line">            <span class="keyword">if</span> y_true[i] != y_true[j]:</span><br><span class="line">                <span class="comment"># Count the pair if it&#x27;s permissible</span></span><br><span class="line">                permissible += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># For permissible pairs, check if they are concordant or are ties</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># check for ties in the score</span></span><br><span class="line">                <span class="keyword">if</span> scores[i] == scores[j]:</span><br><span class="line">                    <span class="comment"># count the tie</span></span><br><span class="line">                    ties += <span class="number">1</span></span><br><span class="line">                    <span class="comment"># if it&#x27;s a tie, we don&#x27;t need to check patient outcomes, continue to the top of the for loop.</span></span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># case 1: patient i doesn&#x27;t get the disease, patient j does</span></span><br><span class="line">                <span class="keyword">if</span> y_true[i] == <span class="number">0</span> <span class="keyword">and</span> y_true[j] == <span class="number">1</span>:</span><br><span class="line">                    <span class="comment"># Check if patient i has a lower risk score than patient j</span></span><br><span class="line">                    <span class="keyword">if</span> scores[i] &lt; scores[j]:</span><br><span class="line">                        <span class="comment"># count the concordant pair</span></span><br><span class="line">                        concordant += <span class="number">1</span></span><br><span class="line">                    <span class="comment"># Otherwise if patient i has a higher risk score, it&#x27;s not a concordant pair.</span></span><br><span class="line">                    <span class="comment"># Already checked for ties earlier</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># case 2: patient i gets the disease, patient j does not</span></span><br><span class="line">                <span class="keyword">if</span> y_true[i] == <span class="number">1</span> <span class="keyword">and</span> y_true[j] == <span class="number">0</span>:</span><br><span class="line">                    <span class="comment"># Check if patient i has a higher risk score than patient j</span></span><br><span class="line">                    <span class="keyword">if</span> scores[i] &gt; scores[j]:</span><br><span class="line">                        <span class="comment">#count the concordant pair</span></span><br><span class="line">                        concordant += <span class="number">1</span></span><br><span class="line">                    <span class="comment"># Otherwise if patient i has a lower risk score, it&#x27;s not a concordant pair.</span></span><br><span class="line">                    <span class="comment"># We already checked for ties earlier</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># calculate the c-index using the count of permissible pairs, concordant pairs, and tied pairs.</span></span><br><span class="line">    c_index = (concordant + <span class="number">0.5</span> * ties) / permissible</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> c_index</span><br></pre></td></tr></table></figure>
<h4 id="test-your-work-2">Test Your Work</h4>
<p>You can use the following test cases to make sure your implementation is correct.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># test</span></span><br><span class="line">y_true = np.array([<span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Case 1</span></span><br><span class="line">scores = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Case 1 Output: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(cindex(y_true, scores)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Case 2</span></span><br><span class="line">scores = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Case 2 Output: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(cindex(y_true, scores)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Case 3</span></span><br><span class="line">scores = np.array([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.0</span>, <span class="number">1.0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Case 3 Output: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(cindex(y_true, scores)))</span><br><span class="line">cindex(y_true, scores)</span><br></pre></td></tr></table></figure>
<pre><code>Case 1 Output: 0.0
Case 2 Output: 1.0
Case 3 Output: 0.875





0.875</code></pre>
<h4 id="expected-output-2">Expected Output:</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Case <span class="number">1</span> Output: <span class="number">0.0</span></span><br><span class="line">Case <span class="number">2</span> Output: <span class="number">1.0</span></span><br><span class="line">Case <span class="number">3</span> Output: <span class="number">0.875</span></span><br></pre></td></tr></table></figure>
<h4 id="note-1">Note</h4>
<p>Please check your implementation of the for loops. - There is way to make a mistake on the for loops that cannot be caught with unit tests. - Bonus: Can you think of what this error could be, and why it can't be caught by unit tests?</p>
<p><a name='7'></a> ## 7. Evaluate the Model on the Test Set</p>
<p>Now, you can evaluate your trained model on the test set.</p>
<p>To get the predicted probabilities, we use the <code>predict_proba</code> method. This method will return the result from the model <em>before</em> it is converted to a binary 0 or 1. For each input case, it returns an array of two values which represent the probabilities for both the negative case (patient does not get the disease) and positive case (patient the gets the disease).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scores = model_X.predict_proba(X_test)[:, <span class="number">1</span>]</span><br><span class="line">c_index_X_test = cindex(y_test.values, scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;c-index on test set is <span class="subst">&#123;c_index_X_test:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>c-index on test set is 0.8182</code></pre>
<h4 id="expected-output-3">Expected output:</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c-index on test set is <span class="number">0.8336</span></span><br></pre></td></tr></table></figure>
<p>Let's plot the coefficients to see which variables (patient features) are having the most effect. You can access the model coefficients by using <code>model.coef_</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">coeffs = pd.DataFrame(data = model_X.coef_, columns = X_train.columns)</span><br><span class="line">coeffs.T.plot.bar(legend=<span class="literal">None</span>);</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_56_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<h3 id="question">Question:</h3>
<blockquote>
<p><strong>Which three variables have the largest impact on the model's predictions?</strong></p>
</blockquote>
<p><a name='8'></a> ## 8. Improve the Model</p>
<p>You can try to improve your model by including interaction terms. * An interaction term is the product of two variables. * For example, if we have data <span class="math display">\[ x = [x_1, x_2]\]</span> * We could add the product so that: <span class="math display">\[ \hat{x} = [x_1, x_2, x_1*x_2]\]</span></p>
<p><a name='Ex-4'></a> ### Exercise 4</p>
<p>Write code below to add all interactions between every pair of variables to the training and test datasets.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_interactions</span>(<span class="params">X</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Add interaction terms between columns to dataframe.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">    X (dataframe): Original data</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    X_int (dataframe): Original data with interaction terms appended. </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    features = X.columns</span><br><span class="line">    m = <span class="built_in">len</span>(features)</span><br><span class="line">    X_int = X.copy(deep=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    <span class="comment"># &#x27;i&#x27; loops through all features in the original dataframe X</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m-<span class="number">1</span>):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># get the name of feature &#x27;i&#x27;</span></span><br><span class="line">        feature_i_name = features[i]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># get the data for feature &#x27;i&#x27;</span></span><br><span class="line">        feature_i_data = X[feature_i_name]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># choose the index of column &#x27;j&#x27; to be greater than column i</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, m):</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># get the name of feature &#x27;j&#x27;</span></span><br><span class="line">            feature_j_name = features[j]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># get the data for feature j&#x27;</span></span><br><span class="line">            feature_j_data = X[feature_j_name]</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># create the name of the interaction feature by combining both names</span></span><br><span class="line">            <span class="comment"># example: &quot;apple&quot; and &quot;orange&quot; are combined to be &quot;apple_x_orange&quot;</span></span><br><span class="line">            feature_i_j_name = feature_i_name + <span class="string">&quot;_x_&quot;</span> + feature_j_name</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Multiply the data for feature &#x27;i&#x27; and feature &#x27;j&#x27;</span></span><br><span class="line">            <span class="comment"># store the result as a column in dataframe X_int</span></span><br><span class="line">            X_int[feature_i_j_name] = feature_i_data * feature_j_data</span><br><span class="line">        </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X_int</span><br></pre></td></tr></table></figure>
<h4 id="test-your-work-3">Test Your Work</h4>
<p>Run the cell below to check your implementation.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Original Data&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(X_train.loc[:, [<span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Systolic_BP&#x27;</span>]].head())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Data w/ Interactions&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(add_interactions(X_train.loc[:, [<span class="string">&#x27;Age&#x27;</span>, <span class="string">&#x27;Systolic_BP&#x27;</span>]].head()))</span><br></pre></td></tr></table></figure>
<pre><code>Original Data
           Age  Systolic_BP
1824 -0.912451    -0.068019
253  -0.302039     1.719538
1114  2.576274     0.155962
3220  1.163621    -2.033931
2108 -0.446238    -0.054554
Data w/ Interactions
           Age  Systolic_BP  Age_x_Systolic_BP
1824 -0.912451    -0.068019           0.062064
253  -0.302039     1.719538          -0.519367
1114  2.576274     0.155962           0.401800
3220  1.163621    -2.033931          -2.366725
2108 -0.446238    -0.054554           0.024344</code></pre>
<h4 id="expected-output-4">Expected Output:</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Original Data</span><br><span class="line">           Age  Systolic_BP</span><br><span class="line"><span class="number">2472</span> <span class="number">-2.340711</span>     <span class="number">0.077089</span></span><br><span class="line"><span class="number">4496</span>  <span class="number">0.009916</span>    <span class="number">-1.324053</span></span><br><span class="line"><span class="number">2243</span>  <span class="number">0.927302</span>    <span class="number">-0.424337</span></span><br><span class="line"><span class="number">4311</span> <span class="number">-0.087282</span>     <span class="number">0.399865</span></span><br><span class="line"><span class="number">843</span>   <span class="number">2.204586</span>     <span class="number">0.025521</span></span><br><span class="line">Data w/ Interactions</span><br><span class="line">           Age  Systolic_BP  Age_x_Systolic_BP</span><br><span class="line"><span class="number">2472</span> <span class="number">-2.340711</span>     <span class="number">0.077089</span>          <span class="number">-0.180444</span></span><br><span class="line"><span class="number">4496</span>  <span class="number">0.009916</span>    <span class="number">-1.324053</span>          <span class="number">-0.013129</span></span><br><span class="line"><span class="number">2243</span>  <span class="number">0.927302</span>    <span class="number">-0.424337</span>          <span class="number">-0.393489</span></span><br><span class="line"><span class="number">4311</span> <span class="number">-0.087282</span>     <span class="number">0.399865</span>          <span class="number">-0.034901</span></span><br><span class="line"><span class="number">843</span>   <span class="number">2.204586</span>     <span class="number">0.025521</span>           <span class="number">0.056264</span></span><br></pre></td></tr></table></figure>
<p>Once you have correctly implemented <code>add_interactions</code>, use it to make transformed version of <code>X_train</code> and <code>X_test</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train_int = add_interactions(X_train)</span><br><span class="line">X_test_int = add_interactions(X_test)</span><br></pre></td></tr></table></figure>
<p><a name='9'></a> ## 9. Evaluate the Improved Model</p>
<p>Now we can train the new and improved version of the model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_X_int = lr_model(X_train_int, y_train)</span><br></pre></td></tr></table></figure>
<p>Let's evaluate our new model on the test set.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scores_X = model_X.predict_proba(X_test)[:, <span class="number">1</span>]</span><br><span class="line">c_index_X_int_test = cindex(y_test.values, scores_X)</span><br><span class="line"></span><br><span class="line">scores_X_int = model_X_int.predict_proba(X_test_int)[:, <span class="number">1</span>]</span><br><span class="line">c_index_X_int_test = cindex(y_test.values, scores_X_int)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;c-index on test set without interactions is <span class="subst">&#123;c_index_X_test:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;c-index on test set with interactions is <span class="subst">&#123;c_index_X_int_test:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>c-index on test set without interactions is 0.8182
c-index on test set with interactions is 0.8281</code></pre>
<p>You should see that the model with interaction terms performs a bit better than the model without interactions.</p>
<p>Now let's take another look at the model coefficients to try and see which variables made a difference. Plot the coefficients and report which features seem to be the most important.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int_coeffs = pd.DataFrame(data = model_X_int.coef_, columns = X_train_int.columns)</span><br><span class="line">int_coeffs.T.plot.bar();</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_71_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<h3 id="questions">Questions:</h3>
<blockquote>
<p><strong>Which variables are most important to the model?</strong><br> <strong>Have the relevant variables changed?</strong><br> <strong>What does it mean when the coefficients are positive or negative?</strong><br></p>
</blockquote>
<p>You may notice that Age, Systolic_BP, and Cholesterol have a positive coefficient. This means that a higher value in these three features leads to a higher prediction probability for the disease. You also may notice that the interaction of Age x Cholesterol has a negative coefficient. This means that a higher value for the Age x Cholesterol product reduces the prediction probability for the disease.</p>
<p>To understand the effect of interaction terms, let's compare the output of the model we've trained on sample cases with and without the interaction. Run the cell below to choose an index and look at the features corresponding to that case in the training set.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">index = index = <span class="number">3432</span></span><br><span class="line">case = X_train_int.iloc[index, :]</span><br><span class="line"><span class="built_in">print</span>(case)</span><br></pre></td></tr></table></figure>
<pre><code>Age                           2.502061
Systolic_BP                   1.713547
Diastolic_BP                  0.268265
Cholesterol                   2.146349
Age_x_Systolic_BP             4.287400
Age_x_Diastolic_BP            0.671216
Age_x_Cholesterol             5.370296
Systolic_BP_x_Diastolic_BP    0.459685
Systolic_BP_x_Cholesterol     3.677871
Diastolic_BP_x_Cholesterol    0.575791
Name: 5970, dtype: float64</code></pre>
<p>We can see that they have above average Age and Cholesterol. We can now see what our original model would have output by zero-ing out the value for Cholesterol and Age.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">new_case = case.copy(deep=<span class="literal">True</span>)</span><br><span class="line">new_case.loc[<span class="string">&quot;Age_x_Cholesterol&quot;</span>] = <span class="number">0</span></span><br><span class="line">new_case</span><br></pre></td></tr></table></figure>
<pre><code>Age                           2.502061
Systolic_BP                   1.713547
Diastolic_BP                  0.268265
Cholesterol                   2.146349
Age_x_Systolic_BP             4.287400
Age_x_Diastolic_BP            0.671216
Age_x_Cholesterol             0.000000
Systolic_BP_x_Diastolic_BP    0.459685
Systolic_BP_x_Cholesterol     3.677871
Diastolic_BP_x_Cholesterol    0.575791
Name: 5970, dtype: float64</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Output with interaction: \t<span class="subst">&#123;model_X_int.predict_proba([case.values])[:, <span class="number">1</span>][<span class="number">0</span>]:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Output without interaction: \t<span class="subst">&#123;model_X_int.predict_proba([new_case.values])[:, <span class="number">1</span>][<span class="number">0</span>]:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Output with interaction:    0.9448
Output without interaction:     0.9965</code></pre>
<h4 id="expected-output-5">Expected output</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Output with interaction: <span class="number">0.9448</span></span><br><span class="line">Output without interaction: <span class="number">0.9965</span></span><br></pre></td></tr></table></figure>
<p>We see that the model is less confident in its prediction with the interaction term than without (the prediction value is lower when including the interaction term). With the interaction term, the model has adjusted for the fact that the effect of high cholesterol becomes less important for older patients compared to younger patients.</p>
<h1 id="congratulations">Congratulations!</h1>
<p>You have finished the first assignment of Course 2.</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Medicine/" rel="tag"># Medicine</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/" rel="prev" title="Brain Tumor Auto-Segmentation for Magnetic Resonance Imaging (MRI)">
      <i class="fa fa-chevron-left"></i> Brain Tumor Auto-Segmentation for Magnetic Resonance Imaging (MRI)
    </a></div>
      <div class="post-nav-item">
    <a href="/Risk-Models-Using-Tree-based-Models/2020/04/18/" rel="next" title="Risk Models Using Tree-based Models">
      Risk Models Using Tree-based Models <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#build-and-evaluate-a-linear-risk-model"><span class="nav-number">1.</span> <span class="nav-text">Build and Evaluate a Linear Risk model</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#outline"><span class="nav-number">1.1.</span> <span class="nav-text">Outline</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#overview-of-the-assignment"><span class="nav-number">1.2.</span> <span class="nav-text">Overview of the Assignment</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#diabetic-retinopathy"><span class="nav-number">1.2.1.</span> <span class="nav-text">Diabetic Retinopathy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#logistic-regression"><span class="nav-number">1.2.2.</span> <span class="nav-text">Logistic Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#note"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">Note</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#test-your-work"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">Test Your Work</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output"><span class="nav-number">1.2.2.3.</span> <span class="nav-text">Expected Output:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#transform-training-and-test-data"><span class="nav-number">1.2.2.4.</span> <span class="nav-text">Transform training and test data</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#test-your-work-1"><span class="nav-number">1.2.2.5.</span> <span class="nav-text">Test Your Work</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-1"><span class="nav-number">1.2.2.6.</span> <span class="nav-text">Expected Output:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#test-your-work-2"><span class="nav-number">1.2.2.7.</span> <span class="nav-text">Test Your Work</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-2"><span class="nav-number">1.2.2.8.</span> <span class="nav-text">Expected Output:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#note-1"><span class="nav-number">1.2.2.9.</span> <span class="nav-text">Note</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-3"><span class="nav-number">1.2.2.10.</span> <span class="nav-text">Expected output:</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#question"><span class="nav-number">1.2.3.</span> <span class="nav-text">Question:</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#test-your-work-3"><span class="nav-number">1.2.3.1.</span> <span class="nav-text">Test Your Work</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-4"><span class="nav-number">1.2.3.2.</span> <span class="nav-text">Expected Output:</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#questions"><span class="nav-number">1.2.4.</span> <span class="nav-text">Questions:</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-5"><span class="nav-number">1.2.4.1.</span> <span class="nav-text">Expected output</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#congratulations"><span class="nav-number">2.</span> <span class="nav-text">Congratulations!</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ruochi Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">268</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zhangruochi" title="GitHub  https:&#x2F;&#x2F;github.com&#x2F;zhangruochi" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zrc720@gmail.com" title="E-Mail  mailto:zrc720@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.healthinformaticslab.org/" title="http:&#x2F;&#x2F;www.healthinformaticslab.org" rel="noopener" target="_blank">HILab</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.shihaizhou.com/" title="http:&#x2F;&#x2F;www.shihaizhou.com" rel="noopener" target="_blank">Rose</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/cherish_CX/" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;cherish_CX&#x2F;" rel="noopener" target="_blank">Chunxia</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019  
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ruochi Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'qW3MLcAgcX96sB6qbegeL7rP-gzGzoHsz',
      appKey     : 'GL6JvT9DgGxqYrY5Vj6bXVuv',
      placeholder: "Thank you for your reply",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'en' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>

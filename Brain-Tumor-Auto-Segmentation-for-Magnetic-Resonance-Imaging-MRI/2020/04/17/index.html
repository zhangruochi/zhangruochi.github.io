<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=PingFang SC:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhangruochi.com","root":"/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Image Source Brain Tumor Auto-Segmentation for Magnetic Resonance Imaging (MRI) Welcome to the final part of the &quot;Artificial Intelligence for Medicine&quot; course 1! You will learn how to build a neural">
<meta property="og:type" content="article">
<meta property="og:title" content="Brain Tumor Auto-Segmentation for Magnetic Resonance Imaging (MRI)">
<meta property="og:url" content="https://zhangruochi.com/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/index.html">
<meta property="og:site_name" content="RUOCHI.AI">
<meta property="og:description" content="Image Source Brain Tumor Auto-Segmentation for Magnetic Resonance Imaging (MRI) Welcome to the final part of the &quot;Artificial Intelligence for Medicine&quot; course 1! You will learn how to build a neural">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://miro.medium.com/max/2652/1*eTkBMyqdg9JodNcG_O4-Kw.jpeg">
<meta property="og:image" content="https://miro.medium.com/max/1740/1*yC1Bt3IOzNv8Pp7t1v7F1Q.png">
<meta property="og:image" content="https://zhangruochi.com/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/output_10_0.png">
<meta property="og:image" content="https://zhangruochi.com/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/output_12_0.png">
<meta property="og:image" content="https://zhangruochi.com/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/output_26_0.png">
<meta property="og:image" content="https://zhangruochi.com/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/output_33_0.png">
<meta property="og:image" content="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png">
<meta property="og:image" content="https://www.researchgate.net/publication/328671987/figure/fig4/AS:688210103529478@1541093483784/Calculation-of-the-Dice-similarity-coefficient-The-deformed-contour-of-the-liver-from.ppm">
<meta property="og:image" content="https://zhangruochi.com/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/output_76_0.png">
<meta property="og:image" content="https://zhangruochi.com/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/output_82_1.png">
<meta property="og:image" content="https://zhangruochi.com/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/output_82_3.png">
<meta property="og:image" content="https://zhangruochi.com/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/output_103_0.png">
<meta property="article:published_time" content="2020-04-17T15:10:42.000Z">
<meta property="article:modified_time" content="2020-04-19T15:10:02.000Z">
<meta property="article:author" content="Ruochi Zhang">
<meta property="article:tag" content="Medicine">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://miro.medium.com/max/2652/1*eTkBMyqdg9JodNcG_O4-Kw.jpeg">

<link rel="canonical" href="https://zhangruochi.com/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Brain Tumor Auto-Segmentation for Magnetic Resonance Imaging (MRI) | RUOCHI.AI</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RUOCHI.AI</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://zhangruochi.com/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ruochi Zhang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RUOCHI.AI">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Brain Tumor Auto-Segmentation for Magnetic Resonance Imaging (MRI)
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-04-17 23:10:42" itemprop="dateCreated datePublished" datetime="2020-04-17T23:10:42+08:00">2020-04-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-19 23:10:02" itemprop="dateModified" datetime="2020-04-19T23:10:02+08:00">2020-04-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Artificial-Intelligence/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/Brain-Tumor-Auto-Segmentation-for-Magnetic-Resonance-Imaging-MRI/2020/04/17/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><img src="https://miro.medium.com/max/2652/1*eTkBMyqdg9JodNcG_O4-Kw.jpeg" width="100%"></p>
<p><a target="_blank" rel="noopener" href="https://medium.com/stanford-ai-for-healthcare/its-a-no-brainer-deep-learning-for-brain-mr-images-f60116397472">Image Source</a></p>
<h1 id="brain-tumor-auto-segmentation-for-magnetic-resonance-imaging-mri">Brain Tumor Auto-Segmentation for Magnetic Resonance Imaging (MRI)</h1>
<p>Welcome to the final part of the "Artificial Intelligence for Medicine" course 1!</p>
<p>You will learn how to build a neural network to automatically segment tumor regions in brain, using <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Magnetic_resonance_imaging">MRI (Magnetic Resonance Imaging</a>) scans.</p>
<p>The MRI scan is one of the most common image modalities that we encounter in the radiology field.<br />
Other data modalities include: - <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/CT_scan">Computer Tomography (CT)</a>, - <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Ultrasound">Ultrasound</a> - <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/X-ray">X-Rays</a>.</p>
<p>In this assignment we will be focusing on MRIs but many of our learnings applies to other mentioned modalities as well. We'll walk you through some of the steps of training a deep learning model for segmentation.</p>
<p><strong>You will learn:</strong></p>
<ul>
<li>What is in an MR image</li>
<li>Standard data preparation techniques for MRI datasets</li>
<li>Metrics and loss functions for segmentation</li>
<li>Visualizing and evaluating segmentation models</li>
</ul>
<h2 id="outline">Outline</h2>
<p>Use these links to jump to particular sections of this assignment!</p>
<ul>
<li><a href="#1">1. Dataset</a>
<ul>
<li><a href="#1-1">1.1 What is an MRI?</a></li>
<li><a href="#1-2">1.2 MRI Data Processing</a></li>
<li><a href="#1-3">1.3 Exploring the Dataset</a></li>
<li><a href="#1-4">1.4 Data Preprocessing</a>
<ul>
<li><a href="#1-4-1">1.4.1 Sub-volume Sampling</a></li>
<li><a href="#1-4-2">1.4.2 Standardization</a></li>
</ul></li>
</ul></li>
<li><a href="#2">2. Model: 3D U-Net</a></li>
<li><a href="#3">3. Metrics</a>
<ul>
<li><a href="#3-1">3.1 Dice Coefficient</a></li>
<li><a href="#3-2">3.2 Soft Dice Loss</a></li>
</ul></li>
<li><a href="#4">4. Training</a></li>
<li><a href="#5">5. Evaluation</a>
<ul>
<li><a href="#5-1">5.1 Overall Performance</a></li>
<li><a href="#5-2">5.2 Patch-level Predictions</a></li>
<li><a href="#5-3">5.3 Running on Entire Scans</a></li>
</ul></li>
</ul>
<h2 id="packages">Packages</h2>
<p>In this assignment, we'll make use of the following packages:</p>
<ul>
<li><code>keras</code> is a framework for building deep learning models.</li>
<li><code>keras.backend</code> allows us to perform math operations on tensors.</li>
<li><code>nibabel</code> will let us extract the images and labels from the files in our dataset.</li>
<li><code>numpy</code> is a library for mathematical and scientific operations.</li>
<li><code>pandas</code> is what we'll use to manipulate our data.</li>
</ul>
<h2 id="import-packages">Import Packages</h2>
<p>Run the next cell to import all the necessary packages, dependencies and custom util functions.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> nibabel <span class="keyword">as</span> nib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> backend <span class="keyword">as</span> K </span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> util</span><br></pre></td></tr></table></figure>
<pre><code>Using TensorFlow backend.</code></pre>
<p><a name="1"></a> # 1 Dataset <a name="1-1"></a> ## 1.1 What is an MRI?</p>
<p>Magnetic resonance imaging (MRI) is an advanced imaging technique that is used to observe a variety of diseases and parts of the body.</p>
<p>As we will see later, neural networks can analyze these images individually (as a radiologist would) or combine them into a single 3D volume to make predictions.</p>
<p>At a high level, MRI works by measuring the radio waves emitting by atoms subjected to a magnetic field.</p>
<p><img src="https://miro.medium.com/max/1740/1*yC1Bt3IOzNv8Pp7t1v7F1Q.png"></p>
<p>In this assignment, we'll build a multi-class segmentation model. We'll identify 3 different abnormalities in each image: edemas, non-enhancing tumors, and enhancing tumors.</p>
<p><a name="1-2"></a></p>
<h2 id="mri-data-processing">1.2 MRI Data Processing</h2>
<p>We often encounter MR images in the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/DICOM">DICOM format</a>. - The DICOM format is the output format for most commercial MRI scanners. This type of data can be processed using the <a target="_blank" rel="noopener" href="https://pydicom.github.io/pydicom/stable/getting_started.html">pydicom</a> Python library.</p>
<p>In this assignment, we will be using the data from the <a target="_blank" rel="noopener" href="https://decathlon-10.grand-challenge.org">Decathlon 10 Challenge</a>. This data has been mostly pre-processed for the competition participants, however in real practice, MRI data needs to be significantly pre-preprocessed before we can use it to train our models.</p>
<p><a name="1-3"></a> ## 1.3 Exploring the Dataset</p>
<p>Our dataset is stored in the <a target="_blank" rel="noopener" href="https://nifti.nimh.nih.gov/nifti-1/">NifTI-1 format</a> and we will be using the <a target="_blank" rel="noopener" href="https://github.com/nipy/nibabel">NiBabel library</a> to interact with the files. Each training sample is composed of two separate files:</p>
<p>The first file is an image file containing a 4D array of MR image in the shape of (240, 240, 155, 4). - The first 3 dimensions are the X, Y, and Z values for each point in the 3D volume, which is commonly called a voxel. - The 4th dimension is the values for 4 different sequences - 0: FLAIR: "Fluid Attenuated Inversion Recovery" (FLAIR) - 1: T1w: "T1-weighted" - 2: t1gd: "T1-weighted with gadolinium contrast enhancement" (T1-Gd) - 3: T2w: "T2-weighted"</p>
<p>The second file in each training example is a label file containing a 3D array with the shape of (240, 240, 155).<br />
- The integer values in this array indicate the "label" for each voxel in the corresponding image files: - 0: background - 1: edema - 2: non-enhancing tumor - 3: enhancing tumor</p>
<p>We have access to a total of 484 training images which we will be splitting into a training (80%) and validation (20%) dataset.</p>
<p>Let's begin by looking at one single case and visualizing the data! You have access to 10 different cases via this notebook and we strongly encourage you to explore the data further on your own.</p>
<p>We'll use the <a target="_blank" rel="noopener" href="https://nipy.org/nibabel/nibabel_images.html">NiBabel library</a> to load the image and label for a case. The function is shown below to give you a sense of how it works.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set home directory and data directory</span></span><br><span class="line">HOME_DIR = <span class="string">&quot;./BraTS-Data/&quot;</span></span><br><span class="line">DATA_DIR = HOME_DIR</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_case</span>(<span class="params">image_nifty_file, label_nifty_file</span>):</span></span><br><span class="line">    <span class="comment"># load the image and label file, get the image content and return a numpy array for each</span></span><br><span class="line">    image = np.array(nib.load(image_nifty_file).get_fdata())</span><br><span class="line">    label = np.array(nib.load(label_nifty_file).get_fdata())</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> image, label</span><br></pre></td></tr></table></figure>
<p>We'll now visualize an example. For this, we use a pre-defined function we have written in the <code>util.py</code> file that uses <code>matplotlib</code> to generate a summary of the image.</p>
<p>The colors correspond to each class. - Red is edema - Green is a non-enhancing tumor - Blue is an enhancing tumor.</p>
<p>Do feel free to look at this function at your own time to understand how this is achieved.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">image, label = load_case(DATA_DIR + <span class="string">&quot;imagesTr/BRATS_003.nii.gz&quot;</span>, DATA_DIR + <span class="string">&quot;labelsTr/BRATS_003.nii.gz&quot;</span>)</span><br><span class="line">image = util.get_labeled_image(image, label)</span><br><span class="line"></span><br><span class="line">util.plot_image_grid(image)</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_10_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p>We've also written a utility function which generates a GIF that shows what it looks like to iterate over each axis.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image, label = load_case(DATA_DIR + <span class="string">&quot;imagesTr/BRATS_003.nii.gz&quot;</span>, DATA_DIR + <span class="string">&quot;labelsTr/BRATS_003.nii.gz&quot;</span>)</span><br><span class="line">util.visualize_data_gif(util.get_labeled_image(image, label))</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_12_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p><strong>Reminder:</strong> You can explore more images in the <code>imagesTr</code> directory by changing the image name file.</p>
<p><a name="1-4"></a> ## 1.4 Data Preprocessing using patches</p>
<p>While our dataset is provided to us post-registration and in the NIfTI format, we still have to do some minor pre-processing before feeding the data to our model.</p>
<h5 id="generate-sub-volumes">Generate sub-volumes</h5>
<p>We are going to first generate "patches" of our data which you can think of as sub-volumes of the whole MR images. - The reason that we are generating patches is because a network that can process the entire volume at once will simply not fit inside our current environment's memory/GPU. - Therefore we will be using this common technique to generate spatially consistent sub-volumes of our data, which can be fed into our network. - Specifically, we will be generating randomly sampled sub-volumes of shape [160, 160, 16] from our images. - Furthermore, given that a large portion of the MRI volumes are just brain tissue or black background without any tumors, we want to make sure that we pick patches that at least include some amount of tumor data. - Therefore, we are only going to pick patches that have at most 95% non-tumor regions (so at least 5% tumor). - We do this by filtering the volumes based on the values present in the background labels.</p>
<h5 id="standardization-mean-0-stdev-1">Standardization (mean 0, stdev 1)</h5>
<p>Lastly, given that the values in MR images cover a very wide range, we will standardize the values to have a mean of zero and standard deviation of 1. - This is a common technique in deep image processing since standardization makes it much easier for the network to learn.</p>
<p>Let's walk through these steps in the following exercises.</p>
<p><a name="1-4-1"></a> ### 1.4.1 Sub-volume Sampling Fill in the function below takes in: - a 4D image (shape: [240, 240, 155, 4]) - its 3D label (shape: [240, 240, 155]) arrays,</p>
<p>The function returns: - A randomly generated sub-volume of size [160, 160, 16] - Its corresponding label in a 1-hot format which has the shape [3, 160, 160, 160]</p>
<p>Additionally: 1. Make sure that at most 95% of the returned patch is non-tumor regions. 2. Given that our network expects the channels for our images to appear as the first dimension (instead of the last one in our current setting) reorder the dimensions of the image to have the channels appear as the first dimension. 3. Reorder the dimensions of the label array to have the first dimension as the classes (instead of the last one in our current setting) 4. Reduce the labels array dimension to only include the non-background classes (total of 3 instead of 4)</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Check the lecture notebook for a similar example in 1 dimension
</li>
<li>
To check the ratio of background to the whole sub-volume, the numerator is the number of background labels in the sub-volume. The last dimension of the label array at index 0 contains the labels to identify whether the voxel is a background (value of 1) or not a a background (value of 0).
</li>
<li>
For the denominator of the background ratio, this is the volume of the output (see <code>output_x</code>, <code>output_y</code>, <code>output_z</code> in the function parameters).
</li>
<li>
<a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical">keras.utils.to_categorical(y, num_classes=)</a>
</li>
<li>
<a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.moveaxis.html" > np.moveaxis </a> can help you re-arrange the dimensions of the arrays
</li>
<li>
<a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.randint.html">np.random.randint</a> for random sampling
</li>
<li>
When taking a subset of the label <code>'y'</code> that excludes the background class, remember which dimension contains the <code>'num_classes'</code> channel after re-ordering the axes.
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_sub_volume</span>(<span class="params">image, label, </span></span></span><br><span class="line"><span class="params"><span class="function">                   orig_x = <span class="number">240</span>, orig_y = <span class="number">240</span>, orig_z = <span class="number">155</span>, </span></span></span><br><span class="line"><span class="params"><span class="function">                   output_x = <span class="number">160</span>, output_y = <span class="number">160</span>, output_z = <span class="number">16</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                   num_classes = <span class="number">4</span>, max_tries = <span class="number">1000</span>, </span></span></span><br><span class="line"><span class="params"><span class="function">                   background_threshold=<span class="number">0.95</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Extract random sub-volume from original images.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        image (np.array): original image, </span></span><br><span class="line"><span class="string">            of shape (orig_x, orig_y, orig_z, num_channels)</span></span><br><span class="line"><span class="string">        label (np.array): original label. </span></span><br><span class="line"><span class="string">            labels coded using discrete values rather than</span></span><br><span class="line"><span class="string">            a separate dimension, </span></span><br><span class="line"><span class="string">            so this is of shape (orig_x, orig_y, orig_z)</span></span><br><span class="line"><span class="string">        orig_x (int): x_dim of input image</span></span><br><span class="line"><span class="string">        orig_y (int): y_dim of input image</span></span><br><span class="line"><span class="string">        orig_z (int): z_dim of input image</span></span><br><span class="line"><span class="string">        output_x (int): desired x_dim of output</span></span><br><span class="line"><span class="string">        output_y (int): desired y_dim of output</span></span><br><span class="line"><span class="string">        output_z (int): desired z_dim of output</span></span><br><span class="line"><span class="string">        num_classes (int): number of class labels</span></span><br><span class="line"><span class="string">        max_tries (int): maximum trials to do when sampling</span></span><br><span class="line"><span class="string">        background_threshold (float): limit on the fraction </span></span><br><span class="line"><span class="string">            of the sample which can be the background</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    returns:</span></span><br><span class="line"><span class="string">        X (np.array): sample of original image of dimension </span></span><br><span class="line"><span class="string">            (num_channels, output_x, output_y, output_z)</span></span><br><span class="line"><span class="string">        y (np.array): labels which correspond to X, of dimension </span></span><br><span class="line"><span class="string">            (num_classes, output_x, output_y, output_z)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Initialize features and labels with `None`</span></span><br><span class="line">    X = <span class="literal">None</span></span><br><span class="line">    y = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    tries = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> tries &lt; max_tries:</span><br><span class="line">        <span class="comment"># randomly sample sub-volume by sampling the corner voxel</span></span><br><span class="line">        <span class="comment"># hint: make sure to leave enough room for the output dimensions!</span></span><br><span class="line">        start_x = np.random.randint(orig_x - output_x + <span class="number">1</span> )</span><br><span class="line">        start_y = np.random.randint(orig_y - output_y + <span class="number">1</span> )</span><br><span class="line">        start_z = np.random.randint(orig_z - output_z + <span class="number">1</span> )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># extract relevant area of label</span></span><br><span class="line">        y = label[start_x: start_x + output_x,</span><br><span class="line">                  start_y: start_y + output_y,</span><br><span class="line">                  start_z: start_z + output_z]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># One-hot encode the categories.</span></span><br><span class="line">        <span class="comment"># This adds a 4th dimension, &#x27;num_classes&#x27;</span></span><br><span class="line">        <span class="comment"># (output_x, output_y, output_z, num_classes)</span></span><br><span class="line">        y = keras.utils.to_categorical(y, num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute the background ratio</span></span><br><span class="line">        bgrd_ratio = y[:,:,:, <span class="number">0</span>].<span class="built_in">sum</span>() / (output_x * output_y * output_z)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># increment tries counter</span></span><br><span class="line">        tries += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># if background ratio is below the desired threshold,</span></span><br><span class="line">        <span class="comment"># use that sub-volume.</span></span><br><span class="line">        <span class="comment"># otherwise continue the loop and try another random sub-volume</span></span><br><span class="line">        <span class="keyword">if</span> bgrd_ratio &lt; background_threshold:</span><br><span class="line"></span><br><span class="line">            <span class="comment"># make copy of the sub-volume</span></span><br><span class="line">            X = np.copy(image[start_x: start_x + output_x,</span><br><span class="line">                              start_y: start_y + output_y,</span><br><span class="line">                              start_z: start_z + output_z, :])</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># change dimension of X</span></span><br><span class="line">            <span class="comment"># from (x_dim, y_dim, z_dim, num_channels)</span></span><br><span class="line">            <span class="comment"># to (num_channels, x_dim, y_dim, z_dim)</span></span><br><span class="line">            X = np.moveaxis(X, -<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># change dimension of y</span></span><br><span class="line">            <span class="comment"># from (x_dim, y_dim, z_dim, num_classes)</span></span><br><span class="line">            <span class="comment"># to (num_classes, x_dim, y_dim, z_dim)</span></span><br><span class="line">            y = np.moveaxis(y, -<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment">### END CODE HERE ###</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># take a subset of y that excludes the background class</span></span><br><span class="line">            <span class="comment"># in the &#x27;num_classes&#x27; dimension</span></span><br><span class="line">            y = y[<span class="number">1</span>:, :, :, :]</span><br><span class="line">    </span><br><span class="line">            <span class="keyword">return</span> X, y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># if we&#x27;ve tried max_tries number of samples</span></span><br><span class="line">    <span class="comment"># Give up in order to avoid looping forever.</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Tried <span class="subst">&#123;tries&#125;</span> times to find a sub-volume. Giving up...&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="test-case">Test Case:</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">image = np.zeros((<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>))</span><br><span class="line">label = np.zeros((<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">            image[i, j, k, <span class="number">0</span>] = i*j*k</span><br><span class="line">            label[i, j, k] = k</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;image:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;z = <span class="subst">&#123;k&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(image[:, :, k, <span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;z = <span class="subst">&#123;k&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[:, :, k])</span><br></pre></td></tr></table></figure>
<pre><code>image:
z = 0
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]]
z = 1
[[0. 0. 0. 0.]
 [0. 1. 2. 3.]
 [0. 2. 4. 6.]
 [0. 3. 6. 9.]]
z = 2
[[ 0.  0.  0.  0.]
 [ 0.  2.  4.  6.]
 [ 0.  4.  8. 12.]
 [ 0.  6. 12. 18.]]


label:
z = 0
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]]
z = 1
[[1. 1. 1. 1.]
 [1. 1. 1. 1.]
 [1. 1. 1. 1.]
 [1. 1. 1. 1.]]
z = 2
[[2. 2. 2. 2.]
 [2. 2. 2. 2.]
 [2. 2. 2. 2.]
 [2. 2. 2. 2.]]</code></pre>
<h4 id="test-extracting-2-2-2-sub-volume">Test: Extracting (2, 2, 2) sub-volume</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sample_image, sample_label = get_sub_volume(image, </span><br><span class="line">                                            label,</span><br><span class="line">                                            orig_x=<span class="number">4</span>, </span><br><span class="line">                                            orig_y=<span class="number">4</span>, </span><br><span class="line">                                            orig_z=<span class="number">3</span>,</span><br><span class="line">                                            output_x=<span class="number">2</span>, </span><br><span class="line">                                            output_y=<span class="number">2</span>, </span><br><span class="line">                                            output_z=<span class="number">2</span>,</span><br><span class="line">                                            num_classes = <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sampled Image:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;z = &quot;</span> + <span class="built_in">str</span>(k))</span><br><span class="line">    <span class="built_in">print</span>(sample_image[<span class="number">0</span>, :, :, k])</span><br></pre></td></tr></table></figure>
<pre><code>Sampled Image:
z = 0
[[0. 2.]
 [0. 3.]]
z = 1
[[0. 4.]
 [0. 6.]]</code></pre>
<h4 id="expected-output">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Sampled Image:</span><br><span class="line">z = <span class="number">0</span></span><br><span class="line">[[<span class="number">0.</span> <span class="number">2.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">3.</span>]]</span><br><span class="line">z = <span class="number">1</span></span><br><span class="line">[[<span class="number">0.</span> <span class="number">4.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">6.</span>]]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Sampled Label:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = &quot;</span> + <span class="built_in">str</span>(c))</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;z = &quot;</span> + <span class="built_in">str</span>(k))</span><br><span class="line">        <span class="built_in">print</span>(sample_label[c, :, :, k])</span><br></pre></td></tr></table></figure>
<pre><code>Sampled Label:
class = 0
z = 0
[[1. 1.]
 [1. 1.]]
z = 1
[[0. 0.]
 [0. 0.]]
class = 1
z = 0
[[0. 0.]
 [0. 0.]]
z = 1
[[1. 1.]
 [1. 1.]]</code></pre>
<h4 id="expected-output-1">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Sampled Label:</span><br><span class="line"><span class="class"><span class="keyword">class</span> = 0</span></span><br><span class="line"><span class="class"><span class="title">z</span> = 0</span></span><br><span class="line"><span class="class">[[1. 1.]</span></span><br><span class="line"><span class="class"> [1. 1.]]</span></span><br><span class="line"><span class="class"><span class="title">z</span> = 1</span></span><br><span class="line"><span class="class">[[0. 0.]</span></span><br><span class="line"><span class="class"> [0. 0.]]</span></span><br><span class="line"><span class="class"><span class="title">class</span> = 1</span></span><br><span class="line"><span class="class"><span class="title">z</span> = 0</span></span><br><span class="line"><span class="class">[[0. 0.]</span></span><br><span class="line"><span class="class"> [0. 0.]]</span></span><br><span class="line"><span class="class"><span class="title">z</span> = 1</span></span><br><span class="line"><span class="class">[[1. 1.]</span></span><br><span class="line"><span class="class"> [1. 1.]]</span></span><br></pre></td></tr></table></figure>
<p>You can run the following cell to look at a candidate patch and ensure that the function works correctly. We'll look at the enhancing tumor part of the label.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">image, label = load_case(DATA_DIR + <span class="string">&quot;imagesTr/BRATS_001.nii.gz&quot;</span>, DATA_DIR + <span class="string">&quot;labelsTr/BRATS_001.nii.gz&quot;</span>)</span><br><span class="line">X, y = get_sub_volume(image, label)</span><br><span class="line"><span class="comment"># enhancing tumor is channel 2 in the class label</span></span><br><span class="line"><span class="comment"># you can change indexer for y to look at different classes</span></span><br><span class="line">util.visualize_patch(X[<span class="number">0</span>, :, :, :], y[<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_26_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p><a name="1-4-2"></a> ### 1.4.2 Standardization</p>
<p>Next, fill in the following function that given a patch (sub-volume), standardizes the values across each channel and each Z plane to have a mean of zero and standard deviation of 1.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Check that the standard deviation is not zero before dividing by it.
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">standardize</span>(<span class="params">image</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Standardize mean and standard deviation </span></span><br><span class="line"><span class="string">        of each channel and z_dimension.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        image (np.array): input image, </span></span><br><span class="line"><span class="string">            shape (num_channels, dim_x, dim_y, dim_z)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        standardized_image (np.array): standardized version of input image</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># initialize to array of zeros, with same shape as the image</span></span><br><span class="line">    standardized_image = np.empty(image.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># iterate over channels</span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(image.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="comment"># iterate over the `z` dimension</span></span><br><span class="line">        <span class="keyword">for</span> z <span class="keyword">in</span> <span class="built_in">range</span>(image.shape[<span class="number">3</span>]):</span><br><span class="line">            <span class="comment"># get a slice of the image </span></span><br><span class="line">            <span class="comment"># at channel c and z-th dimension `z`</span></span><br><span class="line">            image_slice = image[c,:,:,z]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># subtract the mean from image_slice</span></span><br><span class="line">            centered = image_slice - image_slice.mean()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> image_slice.std() != <span class="number">0</span>:</span><br><span class="line">                centered_scaled = image_slice / image_slice.std()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                centered_scaled = centered</span><br><span class="line">                </span><br><span class="line"></span><br><span class="line">            <span class="comment"># update  the slice of standardized image</span></span><br><span class="line">            <span class="comment"># with the scaled centered and scaled image</span></span><br><span class="line">            standardized_image[c, :, :, z] = centered_scaled</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> standardized_image</span><br></pre></td></tr></table></figure>
<p>And to sanity check, let's look at the output of our function:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X_norm = standardize(X)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;standard deviation for a slice should be 1.0&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;stddv for X_norm[0, :, :, 0]: <span class="subst">&#123;X_norm[<span class="number">0</span>,:,:,<span class="number">0</span>].std():<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>standard deviation for a slice should be 1.0
stddv for X_norm[0, :, :, 0]: 1.00</code></pre>
<p>Let's visualize our patch again just to make sure (it won't look different since the <code>imshow</code> function we use to visualize automatically normalizes the pixels when displaying in black and white).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">util.visualize_patch(X_norm[<span class="number">0</span>, :, :, :], y[<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_33_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<p><a name="2"></a> # 2 Model: 3D U-Net Now let's build our model. In this assignment we will be building a <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.06650">3D U-net</a>. - This architecture will take advantage of the volumetric shape of MR images and is one of the best performing models for this task. - Feel free to familiarize yourself with the architecture by reading <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.06650">this paper</a>.</p>
<p><img src="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png" width="50%"></p>
<p><a name="3"></a> # 3 Metrics</p>
<p><a name="3-1"></a> ## 3.1 Dice Similarity Coefficient</p>
<p>Aside from the architecture, one of the most important elements of any deep learning method is the choice of our loss function.</p>
<p>A natural choice that you may be familiar with is the cross-entropy loss function. - However, this loss function is not ideal for segmentation tasks due to heavy class imbalance (there are typically not many positive regions).</p>
<p>A much more common loss for segmentation tasks is the Dice similarity coefficient, which is a measure of how well two contours overlap. - The Dice index ranges from 0 (complete mismatch) - To 1 (perfect match).</p>
<p>In general, for two sets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, the Dice similarity coefficient is defined as: <span class="math display">\[\text{DSC}(A, B) = \frac{2 \times |A \cap B|}{|A| + |B|}.\]</span></p>
<p>Here we can interpret <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> as sets of voxels, <span class="math inline">\(A\)</span> being the predicted tumor region and <span class="math inline">\(B\)</span> being the ground truth.</p>
<p>Our model will map each voxel to 0 or 1 - 0 means it is a background voxel - 1 means it is part of the segmented region.</p>
<p>In the dice coefficient, the variables in the formula are: - <span class="math inline">\(x\)</span> : the input image - <span class="math inline">\(f(x)\)</span> : the model output (prediction) - <span class="math inline">\(y\)</span> : the label (actual ground truth)</p>
<p>The dice coefficient "DSC" is:</p>
<p><span class="math display">\[\text{DSC}(f, x, y) = \frac{2 \times \sum_{i, j} f(x)_{ij} \times y_{ij} + \epsilon}{\sum_{i,j} f(x)_{ij} + \sum_{i, j} y_{ij} + \epsilon}\]</span></p>
<ul>
<li><span class="math inline">\(\epsilon\)</span> is a small number that is added to avoid division by zero</li>
</ul>
<p><img src="https://www.researchgate.net/publication/328671987/figure/fig4/AS:688210103529478@1541093483784/Calculation-of-the-Dice-similarity-coefficient-The-deformed-contour-of-the-liver-from.ppm" width="30%"></p>
<p><a target="_blank" rel="noopener" href="https://www.researchgate.net/figure/Calculation-of-the-Dice-similarity-coefficient-The-deformed-contour-of-the-liver-from_fig4_328671987">Image Source</a></p>
<p>Implement the dice coefficient for a single output class below.</p>
<ul>
<li>Please use the <a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/backend/sum">Keras.sum(x,axis=)</a> function to compute the numerator and denominator of the dice coefficient.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">single_class_dice_coefficient</span>(<span class="params">y_true, y_pred, axis=(<span class="params"><span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span></span>), </span></span></span><br><span class="line"><span class="params"><span class="function">                                  epsilon=<span class="number">0.00001</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute dice coefficient for single class.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        y_true (Tensorflow tensor): tensor of ground truth values for single class.</span></span><br><span class="line"><span class="string">                                    shape: (x_dim, y_dim, z_dim)</span></span><br><span class="line"><span class="string">        y_pred (Tensorflow tensor): tensor of predictions for single class.</span></span><br><span class="line"><span class="string">                                    shape: (x_dim, y_dim, z_dim)</span></span><br><span class="line"><span class="string">        axis (tuple): spatial axes to sum over when computing numerator and</span></span><br><span class="line"><span class="string">                      denominator of dice coefficient.</span></span><br><span class="line"><span class="string">                      Hint: pass this as the &#x27;axis&#x27; argument to the K.sum function.</span></span><br><span class="line"><span class="string">        epsilon (float): small constant added to numerator and denominator to</span></span><br><span class="line"><span class="string">                        avoid divide by 0 errors.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        dice_coefficient (float): computed value of dice coefficient.     </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    dice_numerator = K.<span class="built_in">sum</span>(<span class="number">2</span> * y_true * y_pred, axis= axis) + epsilon</span><br><span class="line">    dice_denominator = K.<span class="built_in">sum</span>(y_true,axis= axis) + K.<span class="built_in">sum</span>(y_pred, axis = axis) + epsilon</span><br><span class="line">    dice_coefficient = dice_numerator / dice_denominator </span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dice_coefficient</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TEST CASES</span></span><br><span class="line">sess = K.get_session()</span><br><span class="line"><span class="comment">#sess = tf.compat.v1.Session()</span></span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    pred = np.expand_dims(np.eye(<span class="number">2</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #1&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[:, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[:, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># choosing a large epsilon to help check for implementation errors</span></span><br><span class="line">    dc = single_class_dice_coefficient(pred, label,epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;dice coefficient: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #2&quot;</span>)</span><br><span class="line">    pred = np.expand_dims(np.eye(<span class="number">2</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]]), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[:, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[:, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># choosing a large epsilon to help check for implementation errors</span></span><br><span class="line">    dc = single_class_dice_coefficient(pred, label,epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;dice_coefficient: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #1
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 0.]]
dice coefficient: 0.6000


Test Case #2
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 1.]]
dice_coefficient: 0.8333</code></pre>
<h5 id="expected-output-2">Expected output</h5>
<p>If you get a different result, please check that you implemented the equation completely. <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#1</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span>]]</span><br><span class="line">dice coefficient: <span class="number">0.6000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Test Case <span class="comment">#2</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">dice_coefficient: <span class="number">0.8333</span></span><br></pre></td></tr></table></figure></p>
<h3 id="dice-coefficient-for-multiple-classes">Dice Coefficient for Multiple classes</h3>
<p>Now that we have the single class case, we can think about how to approach the multi class context. - Remember that for this task, we want segmentations for each of the 3 classes of abnormality (edema, enhancing tumor, non-enhancing tumor). - This will give us 3 different dice coefficients (one for each abnormality class). - To combine these, we can just take the average. We can write that the overall dice coefficient is:</p>
<p><span class="math display">\[DC(f, x, y) = \frac{1}{3} \left ( DC_{1}(f, x, y) + DC_{2}(f, x, y) + DC_{3}(f, x, y) \right )\]</span></p>
<ul>
<li><span class="math inline">\(DC_{1}\)</span>, <span class="math inline">\(DC_{2}\)</span> and <span class="math inline">\(DC_{3}\)</span> are edema, enhancing tumor, and non-enhancing tumor dice coefficients.</li>
</ul>
<p>For any number of classes, the equation becomes:<br />
<span class="math display">\[DC(f, x, y) = \frac{1}{N} \sum_{c=1}^{C} \left ( DC_{c}(f, x, y) \right )\]</span></p>
<p>In this case, with three categories, <span class="math inline">\(C = 3\)</span></p>
<p>Implement the mean dice coefficient below. This should not be very different from your singe-class implementation.</p>
<p>Please use the <a target="_blank" rel="noopener" href="https://keras.io/backend/#mean">K.mean</a> function to take the average of the three classes.<br />
- Apply the mean to the ratio that you calculate in the last line of code that you'll implement.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C4 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dice_coefficient</span>(<span class="params">y_true, y_pred, axis=(<span class="params"><span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span></span>), </span></span></span><br><span class="line"><span class="params"><span class="function">                     epsilon=<span class="number">0.00001</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute mean dice coefficient over all abnormality classes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        y_true (Tensorflow tensor): tensor of ground truth values for all classes.</span></span><br><span class="line"><span class="string">                                    shape: (num_classes, x_dim, y_dim, z_dim)</span></span><br><span class="line"><span class="string">        y_pred (Tensorflow tensor): tensor of predictions for all classes.</span></span><br><span class="line"><span class="string">                                    shape: (num_classes, x_dim, y_dim, z_dim)</span></span><br><span class="line"><span class="string">        axis (tuple): spatial axes to sum over when computing numerator and</span></span><br><span class="line"><span class="string">                      denominator of dice coefficient.</span></span><br><span class="line"><span class="string">                      Hint: pass this as the &#x27;axis&#x27; argument to the K.sum</span></span><br><span class="line"><span class="string">                            and K.mean functions.</span></span><br><span class="line"><span class="string">        epsilon (float): small constant add to numerator and denominator to</span></span><br><span class="line"><span class="string">                        avoid divide by 0 errors.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        dice_coefficient (float): computed value of dice coefficient.     </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    dice_numerator = K.<span class="built_in">sum</span>(<span class="number">2</span> * y_true * y_pred, axis= axis) + epsilon</span><br><span class="line">    dice_denominator = K.<span class="built_in">sum</span>(y_true,axis= axis) + K.<span class="built_in">sum</span>(y_pred, axis = axis) + epsilon</span><br><span class="line">    dice_coefficient = K.mean(dice_numerator / dice_denominator,axis = <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dice_coefficient</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TEST CASES</span></span><br><span class="line">sess = K.get_session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #1&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    dc = dice_coefficient(pred, label,epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;dice coefficient: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #2&quot;</span>)</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    dc = dice_coefficient(pred, label,epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;dice coefficient: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #3&quot;</span>)</span><br><span class="line">    pred = np.zeros((<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">    pred[<span class="number">0</span>, :, :, :] = np.expand_dims(np.eye(<span class="number">2</span>), -<span class="number">1</span>)</span><br><span class="line">    pred[<span class="number">1</span>, :, :, :] = np.expand_dims(np.eye(<span class="number">2</span>), -<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    label = np.zeros((<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">    label[<span class="number">0</span>, :, :, :] = np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), -<span class="number">1</span>)</span><br><span class="line">    label[<span class="number">1</span>, :, :, :] = np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]]), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 0&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 1&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">1</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 0&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 1&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">1</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    dc = dice_coefficient(pred, label,epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;dice coefficient: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #1
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 0.]]
dice coefficient: 0.6000


Test Case #2
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 1.]]
dice coefficient: 0.8333


Test Case #3
pred:
class = 0
[[1. 0.]
 [0. 1.]]
class = 1
[[1. 0.]
 [0. 1.]]
label:
class = 0
[[1. 1.]
 [0. 0.]]
class = 1
[[1. 1.]
 [0. 1.]]
dice coefficient: 0.7167</code></pre>
<h4 id="expected-output-3">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#1</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span>]]</span><br><span class="line">dice coefficient: <span class="number">0.6000</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Test Case <span class="comment">#2</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">dice coefficient: <span class="number">0.8333</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Test Case <span class="comment">#3</span></span><br><span class="line">pred:</span><br><span class="line"><span class="class"><span class="keyword">class</span> = 0</span></span><br><span class="line"><span class="class">[[1. 0.]</span></span><br><span class="line"><span class="class"> [0. 1.]]</span></span><br><span class="line"><span class="class"><span class="title">class</span> = 1</span></span><br><span class="line"><span class="class">[[1. 0.]</span></span><br><span class="line"><span class="class"> [0. 1.]]</span></span><br><span class="line"><span class="class"><span class="title">label</span>:</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> = 0</span></span><br><span class="line"><span class="class">[[1. 1.]</span></span><br><span class="line"><span class="class"> [0. 0.]]</span></span><br><span class="line"><span class="class"><span class="title">class</span> = 1</span></span><br><span class="line"><span class="class">[[1. 1.]</span></span><br><span class="line"><span class="class"> [0. 1.]]</span></span><br><span class="line"><span class="class"><span class="title">dice</span> <span class="title">coefficient</span>:</span> <span class="number">0.7167</span></span><br></pre></td></tr></table></figure>
<p><a name="3-2"></a> ## 3.2 Soft Dice Loss</p>
<p>While the Dice Coefficient makes intuitive sense, it is not the best for training. - This is because it takes in discrete values (zeros and ones). - The model outputs <em>probabilities</em> that each pixel is, say, a tumor or not, and we want to be able to backpropagate through those outputs.</p>
<p>Therefore, we need an analogue of the Dice loss which takes real valued input. This is where the <strong>Soft Dice loss</strong> comes in. The formula is:</p>
<p><span class="math display">\[\mathcal{L}_{Dice}(p, q) = 1 - \frac{2\times\sum_{i, j} p_{ij}q_{ij} + \epsilon}{\left(\sum_{i, j} p_{ij}^2 \right) + \left(\sum_{i, j} q_{ij}^2 \right) + \epsilon}\]</span></p>
<ul>
<li><span class="math inline">\(p\)</span> is our predictions</li>
<li><span class="math inline">\(q\)</span> is the ground truth</li>
<li>In practice each <span class="math inline">\(q_i\)</span> will either be 0 or 1.</li>
<li><span class="math inline">\(\epsilon\)</span> is a small number that is added to avoid division by zero</li>
</ul>
<p>The soft Dice loss ranges between - 0: perfectly matching the ground truth distribution <span class="math inline">\(q\)</span> - 1: complete mismatch with the ground truth.</p>
<p>You can also check that if <span class="math inline">\(p_i\)</span> and <span class="math inline">\(q_i\)</span> are each 0 or 1, then the soft Dice loss is just one minus the dice coefficient.</p>
<h3 id="multi-class-soft-dice-loss">Multi-Class Soft Dice Loss</h3>
<p>We've explained the single class case for simplicity, but the multi-class generalization is exactly the same as that of the dice coefficient. - Since you've already implemented the multi-class dice coefficient, we'll have you jump directly to the multi-class soft dice loss.</p>
<p>For any number of categories of diseases, the expression becomes:</p>
<p><span class="math display">\[\mathcal{L}_{Dice}(p, q) = 1 - \frac{1}{N} \sum_{c=1}^{C} \frac{2\times\sum_{i, j} p_{cij}q_{cij} + \epsilon}{\left(\sum_{i, j} p_{cij}^2 \right) + \left(\sum_{i, j} q_{cij}^2 \right) + \epsilon}\]</span></p>
<p>Please implement the soft dice loss below!</p>
<p>As before, you will use K.mean() - Apply the average the mean to ratio that you'll calculate in the last line of code that you'll implement.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">soft_dice_loss</span>(<span class="params">y_true, y_pred, axis=(<span class="params"><span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span></span>), </span></span></span><br><span class="line"><span class="params"><span class="function">                   epsilon=<span class="number">0.00001</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute mean soft dice loss over all abnormality classes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        y_true (Tensorflow tensor): tensor of ground truth values for all classes.</span></span><br><span class="line"><span class="string">                                    shape: (num_classes, x_dim, y_dim, z_dim)</span></span><br><span class="line"><span class="string">        y_pred (Tensorflow tensor): tensor of soft predictions for all classes.</span></span><br><span class="line"><span class="string">                                    shape: (num_classes, x_dim, y_dim, z_dim)</span></span><br><span class="line"><span class="string">        axis (tuple): spatial axes to sum over when computing numerator and</span></span><br><span class="line"><span class="string">                      denominator in formula for dice loss.</span></span><br><span class="line"><span class="string">                      Hint: pass this as the &#x27;axis&#x27; argument to the K.sum</span></span><br><span class="line"><span class="string">                            and K.mean functions.</span></span><br><span class="line"><span class="string">        epsilon (float): small constant added to numerator and denominator to</span></span><br><span class="line"><span class="string">                        avoid divide by 0 errors.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        dice_loss (float): computed value of dice loss.     </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line"></span><br><span class="line">    dice_numerator = <span class="number">2</span> * K.<span class="built_in">sum</span>(y_true * y_pred, axis=axis) + epsilon</span><br><span class="line">    dice_denominator = K.<span class="built_in">sum</span>(K.square(y_true), axis = axis) + K.<span class="built_in">sum</span>(K.square(y_pred), axis = axis) + epsilon</span><br><span class="line">    dice_loss = <span class="number">1</span> - K.mean(dice_numerator / dice_denominator, axis = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dice_loss</span><br></pre></td></tr></table></figure>
<h4 id="test-case-1">Test Case 1</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TEST CASES</span></span><br><span class="line">sess = K.get_session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #1&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    dc = soft_dice_loss(pred, label, epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;soft dice loss:<span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #1
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 0.]]
soft dice loss:0.4000</code></pre>
<h4 id="expected-output-4">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#1</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span>]]</span><br><span class="line">soft dice loss:<span class="number">0.4000</span></span><br></pre></td></tr></table></figure>
<h4 id="test-case-2">Test Case 2</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">sess = K.get_session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #2&quot;</span>)</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(<span class="number">0.5</span>*np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    dc = soft_dice_loss(pred, label, epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;soft dice loss: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #2
pred:
[[0.5 0. ]
 [0.  0.5]]
label:
[[1. 1.]
 [0. 0.]]
soft dice loss: 0.4286</code></pre>
<h4 id="expected-output-5">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#2</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">0.5</span> <span class="number">0.</span> ]</span><br><span class="line"> [<span class="number">0.</span>  <span class="number">0.5</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span>]]</span><br><span class="line">soft dice loss: <span class="number">0.4286</span></span><br></pre></td></tr></table></figure>
<h4 id="test-case-3">Test Case 3</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">sess = K.get_session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #3&quot;</span>)</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    dc = soft_dice_loss(pred, label, epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;soft dice loss: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #3
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 1.]]
soft dice loss: 0.1667</code></pre>
<h4 id="expected-output-6">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#3</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">soft dice loss: <span class="number">0.1667</span></span><br></pre></td></tr></table></figure>
<h4 id="test-case-4">Test Case 4</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">sess = K.get_session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #4&quot;</span>)</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    pred[<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>] = <span class="number">0.8</span></span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    dc = soft_dice_loss(pred, label, epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;soft dice loss: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #4
pred:
[[1.  0.8]
 [0.  1. ]]
label:
[[1. 1.]
 [0. 1.]]
soft dice loss: 0.0060</code></pre>
<h4 id="expected-output-7">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#4</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span>  <span class="number">0.8</span>]</span><br><span class="line"> [<span class="number">0.</span>  <span class="number">1.</span> ]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">soft dice loss: <span class="number">0.0060</span></span><br></pre></td></tr></table></figure>
<h4 id="test-case-5">Test Case 5</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">sess = K.get_session()</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Test Case #5&quot;</span>)</span><br><span class="line">    pred = np.zeros((<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">    pred[<span class="number">0</span>, :, :, :] = np.expand_dims(<span class="number">0.5</span>*np.eye(<span class="number">2</span>), -<span class="number">1</span>)</span><br><span class="line">    pred[<span class="number">1</span>, :, :, :] = np.expand_dims(np.eye(<span class="number">2</span>), -<span class="number">1</span>)</span><br><span class="line">    pred[<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>] = <span class="number">0.8</span></span><br><span class="line"></span><br><span class="line">    label = np.zeros((<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>))</span><br><span class="line">    label[<span class="number">0</span>, :, :, :] = np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), -<span class="number">1</span>)</span><br><span class="line">    label[<span class="number">1</span>, :, :, :] = np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]]), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 0&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 1&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(pred[<span class="number">1</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 0&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;class = 1&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(label[<span class="number">1</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    dc = soft_dice_loss(pred, label, epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;soft dice loss: <span class="subst">&#123;dc.<span class="built_in">eval</span>():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #5
pred:
class = 0
[[0.5 0. ]
 [0.  0.5]]
class = 1
[[1.  0.8]
 [0.  1. ]]
label:
class = 0
[[1. 1.]
 [0. 0.]]
class = 1
[[1. 1.]
 [0. 1.]]
soft dice loss: 0.2173</code></pre>
<h4 id="expected-output-8">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#5</span></span><br><span class="line">pred:</span><br><span class="line"><span class="class"><span class="keyword">class</span> = 0</span></span><br><span class="line"><span class="class">[[0.5 0. ]</span></span><br><span class="line"><span class="class"> [0.  0.5]]</span></span><br><span class="line"><span class="class"><span class="title">class</span> = 1</span></span><br><span class="line"><span class="class">[[1.  0.8]</span></span><br><span class="line"><span class="class"> [0.  1. ]]</span></span><br><span class="line"><span class="class"><span class="title">label</span>:</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> = 0</span></span><br><span class="line"><span class="class">[[1. 1.]</span></span><br><span class="line"><span class="class"> [0. 0.]]</span></span><br><span class="line"><span class="class"><span class="title">class</span> = 1</span></span><br><span class="line"><span class="class">[[1. 1.]</span></span><br><span class="line"><span class="class"> [0. 1.]]</span></span><br><span class="line"><span class="class"><span class="title">soft</span> <span class="title">dice</span> <span class="title">loss</span>:</span> <span class="number">0.2173</span></span><br></pre></td></tr></table></figure>
<h4 id="test-case-6">Test Case 6</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test case 6</span></span><br><span class="line">pred = np.array([</span><br><span class="line">                    [</span><br><span class="line">                        [ </span><br><span class="line">                            [<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">                        ],</span><br><span class="line">                        [</span><br><span class="line">                            [<span class="number">1.0</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]</span><br><span class="line">                        ]</span><br><span class="line">                    ],</span><br><span class="line">                    [</span><br><span class="line">                        [ </span><br><span class="line">                            [<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">                        ],</span><br><span class="line">                        [</span><br><span class="line">                            [<span class="number">1.0</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]</span><br><span class="line">                        ]</span><br><span class="line">                    ],</span><br><span class="line">                  ])</span><br><span class="line">label = np.array([</span><br><span class="line">                    [</span><br><span class="line">                        [ </span><br><span class="line">                            [<span class="number">1.0</span>, <span class="number">0.0</span>], [<span class="number">1.0</span>, <span class="number">0.0</span>]</span><br><span class="line">                        ],</span><br><span class="line">                        [</span><br><span class="line">                            [<span class="number">1.0</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">                        ]</span><br><span class="line">                    ],</span><br><span class="line">                    [</span><br><span class="line">                        [ </span><br><span class="line">                            [<span class="number">0.0</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">                        ],</span><br><span class="line">                        [</span><br><span class="line">                            [<span class="number">1.0</span>, <span class="number">0.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line">                        ]</span><br><span class="line">                    ]</span><br><span class="line">                  ])</span><br><span class="line"></span><br><span class="line">sess = K.get_session()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test case #6&quot;</span>)</span><br><span class="line"><span class="keyword">with</span> sess.as_default() <span class="keyword">as</span> sess:</span><br><span class="line">    dc = soft_dice_loss(pred, label, epsilon=<span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;soft dice loss&quot;</span>,dc.<span class="built_in">eval</span>())</span><br></pre></td></tr></table></figure>
<pre><code>Test case #6
soft dice loss 0.4375</code></pre>
<h4 id="expected-output-9">Expected Output</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Test case <span class="comment">#6</span></span><br><span class="line">soft dice loss: <span class="number">0.4375</span></span><br></pre></td></tr></table></figure>
<p>Note, if you don't have a scalar, and have an array with more than one value, please check your implementation!</p>
<p><a name="4"></a> # 4 Create and Train the model</p>
<p>Once you've finished implementing the soft dice loss, we can create the model!</p>
<p>We'll use the <code>unet_model_3d</code> function in <code>utils</code> which we implemented for you. - This creates the model architecture and compiles the model with the specified loss functions and metrics. - Check out function <code>util.unet_model_3d(loss_function)</code> in the <code>util.py</code> file.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = util.unet_model_3d(loss_function=soft_dice_loss, metrics=[dice_coefficient])</span><br></pre></td></tr></table></figure>
<pre><code>WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.</code></pre>
<p><a name="4-1"></a> ## 4.1 Training on a Large Dataset</p>
<p>In order to facilitate the training on the large dataset: - We have pre-processed the entire dataset into patches and stored the patches in the <a target="_blank" rel="noopener" href="http://docs.h5py.org/en/stable/"><code>h5py</code></a> format. - We also wrote a custom Keras <a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence"><code>Sequence</code></a> class which can be used as a <code>Generator</code> for the keras model to train on large datasets. - Feel free to look at the <code>VolumeDataGenerator</code> class in <code>util.py</code> to learn about how such a generator can be coded.</p>
<p>Note: <a target="_blank" rel="noopener" href="https://www.geeksforgeeks.org/keras-fit-and-keras-fit_generator/">Here</a> you can check the difference between <code>fit</code> and <code>fit_generator</code> functions.</p>
<p>To get a flavor of the training on the larger dataset, you can run the following cell to train the model on a small subset of the dataset (85 patches). You should see the loss going down and the dice coefficient going up.</p>
<p>Running <code>model.fit()</code> on the Coursera workspace may cause the kernel to die. - Soon, we will load a pre-trained version of this model, so that you don't need to train the model on this workspace.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Run this on your local machine only</span></span><br><span class="line"><span class="comment"># May cause the kernel to die if running in the Coursera platform</span></span><br><span class="line"></span><br><span class="line">base_dir = HOME_DIR + <span class="string">&quot;processed/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(base_dir + <span class="string">&quot;config.json&quot;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    config = json.load(json_file)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get generators for training and validation sets</span></span><br><span class="line">train_generator = util.VolumeDataGenerator(config[<span class="string">&quot;train&quot;</span>], base_dir + <span class="string">&quot;train/&quot;</span>, batch_size=<span class="number">3</span>, dim=(<span class="number">160</span>, <span class="number">160</span>, <span class="number">16</span>), verbose=<span class="number">0</span>)</span><br><span class="line">valid_generator = util.VolumeDataGenerator(config[<span class="string">&quot;valid&quot;</span>], base_dir + <span class="string">&quot;valid/&quot;</span>, batch_size=<span class="number">3</span>, dim=(<span class="number">160</span>, <span class="number">160</span>, <span class="number">16</span>), verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">steps_per_epoch = <span class="number">20</span></span><br><span class="line">n_epochs=<span class="number">10</span></span><br><span class="line">validation_steps = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">model.fit_generator(generator=train_generator,</span><br><span class="line">        steps_per_epoch=steps_per_epoch,</span><br><span class="line">        epochs=n_epochs,</span><br><span class="line">        use_multiprocessing=<span class="literal">True</span>,</span><br><span class="line">        validation_data=valid_generator,</span><br><span class="line">        validation_steps=validation_steps)</span><br><span class="line"></span><br><span class="line"><span class="comment"># run this cell if you to save the weights of your trained model in cell section 4.1</span></span><br><span class="line"><span class="comment">#model.save_weights(base_dir + &#x27;my_model_pretrained.hdf5&#x27;)</span></span><br></pre></td></tr></table></figure>
<p><a name="4-2"></a> ## 4.2 Loading a Pre-Trained Model As in assignment 1, instead of having the model train for longer, we'll give you access to a pretrained version. We'll use this to extract predictions and measure performance.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># run this cell if you didn&#x27;t run the training cell in section 4.1</span></span><br><span class="line">base_dir = HOME_DIR + <span class="string">&quot;processed/&quot;</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(base_dir + <span class="string">&quot;config.json&quot;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    config = json.load(json_file)</span><br><span class="line"><span class="comment"># Get generators for training and validation sets</span></span><br><span class="line">train_generator = util.VolumeDataGenerator(config[<span class="string">&quot;train&quot;</span>], base_dir + <span class="string">&quot;train/&quot;</span>, batch_size=<span class="number">3</span>, dim=(<span class="number">160</span>, <span class="number">160</span>, <span class="number">16</span>), verbose=<span class="number">0</span>)</span><br><span class="line">valid_generator = util.VolumeDataGenerator(config[<span class="string">&quot;valid&quot;</span>], base_dir + <span class="string">&quot;valid/&quot;</span>, batch_size=<span class="number">3</span>, dim=(<span class="number">160</span>, <span class="number">160</span>, <span class="number">16</span>), verbose=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_weights(HOME_DIR + <span class="string">&quot;model_pretrained.hdf5&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;model_1&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4, 160, 160,  0                                            
__________________________________________________________________________________________________
conv3d_1 (Conv3D)               (None, 32, 160, 160, 3488        input_1[0][0]                    
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 32, 160, 160, 0           conv3d_1[0][0]                   
__________________________________________________________________________________________________
conv3d_2 (Conv3D)               (None, 64, 160, 160, 55360       activation_1[0][0]               
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 64, 160, 160, 0           conv3d_2[0][0]                   
__________________________________________________________________________________________________
max_pooling3d_1 (MaxPooling3D)  (None, 64, 80, 80, 8 0           activation_2[0][0]               
__________________________________________________________________________________________________
conv3d_3 (Conv3D)               (None, 64, 80, 80, 8 110656      max_pooling3d_1[0][0]            
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 64, 80, 80, 8 0           conv3d_3[0][0]                   
__________________________________________________________________________________________________
conv3d_4 (Conv3D)               (None, 128, 80, 80,  221312      activation_3[0][0]               
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 128, 80, 80,  0           conv3d_4[0][0]                   
__________________________________________________________________________________________________
max_pooling3d_2 (MaxPooling3D)  (None, 128, 40, 40,  0           activation_4[0][0]               
__________________________________________________________________________________________________
conv3d_5 (Conv3D)               (None, 128, 40, 40,  442496      max_pooling3d_2[0][0]            
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 128, 40, 40,  0           conv3d_5[0][0]                   
__________________________________________________________________________________________________
conv3d_6 (Conv3D)               (None, 256, 40, 40,  884992      activation_5[0][0]               
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 256, 40, 40,  0           conv3d_6[0][0]                   
__________________________________________________________________________________________________
max_pooling3d_3 (MaxPooling3D)  (None, 256, 20, 20,  0           activation_6[0][0]               
__________________________________________________________________________________________________
conv3d_7 (Conv3D)               (None, 256, 20, 20,  1769728     max_pooling3d_3[0][0]            
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 256, 20, 20,  0           conv3d_7[0][0]                   
__________________________________________________________________________________________________
conv3d_8 (Conv3D)               (None, 512, 20, 20,  3539456     activation_7[0][0]               
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 512, 20, 20,  0           conv3d_8[0][0]                   
__________________________________________________________________________________________________
up_sampling3d_1 (UpSampling3D)  (None, 512, 40, 40,  0           activation_8[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 768, 40, 40,  0           up_sampling3d_1[0][0]            
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
conv3d_9 (Conv3D)               (None, 256, 40, 40,  5308672     concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 256, 40, 40,  0           conv3d_9[0][0]                   
__________________________________________________________________________________________________
conv3d_10 (Conv3D)              (None, 256, 40, 40,  1769728     activation_9[0][0]               
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 256, 40, 40,  0           conv3d_10[0][0]                  
__________________________________________________________________________________________________
up_sampling3d_2 (UpSampling3D)  (None, 256, 80, 80,  0           activation_10[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 384, 80, 80,  0           up_sampling3d_2[0][0]            
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv3d_11 (Conv3D)              (None, 128, 80, 80,  1327232     concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 128, 80, 80,  0           conv3d_11[0][0]                  
__________________________________________________________________________________________________
conv3d_12 (Conv3D)              (None, 128, 80, 80,  442496      activation_11[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 128, 80, 80,  0           conv3d_12[0][0]                  
__________________________________________________________________________________________________
up_sampling3d_3 (UpSampling3D)  (None, 128, 160, 160 0           activation_12[0][0]              
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 192, 160, 160 0           up_sampling3d_3[0][0]            
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv3d_13 (Conv3D)              (None, 64, 160, 160, 331840      concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 64, 160, 160, 0           conv3d_13[0][0]                  
__________________________________________________________________________________________________
conv3d_14 (Conv3D)              (None, 64, 160, 160, 110656      activation_13[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 64, 160, 160, 0           conv3d_14[0][0]                  
__________________________________________________________________________________________________
conv3d_15 (Conv3D)              (None, 3, 160, 160,  195         activation_14[0][0]              
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 3, 160, 160,  0           conv3d_15[0][0]                  
==================================================================================================
Total params: 16,318,307
Trainable params: 16,318,307
Non-trainable params: 0
__________________________________________________________________________________________________</code></pre>
<p><a name="5"></a> # 5 Evaluation</p>
<p>Now that we have a trained model, we'll learn to extract its predictions and evaluate its performance on scans from our validation set.</p>
<p><a name="5-1"></a> ## 5.1 Overall Performance</p>
<p>First let's measure the overall performance on the validation set. - We can do this by calling the keras <a target="_blank" rel="noopener" href="https://keras.io/models/model/#evaluate_generator">evaluate_generator</a> function and passing in the validation generator, created in section 4.1.</p>
<h4 id="using-the-validation-set-for-testing">Using the validation set for testing</h4>
<ul>
<li>Note: since we didn't do cross validation tuning on the final model, it's okay to use the validation set.</li>
<li>For real life implementations, however, you would want to do cross validation as usual to choose hyperparamters and then use a hold out test set to assess performance</li>
</ul>
<p>Python Code for measuring the overall performance on the validation set:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">val_loss, val_dice = model.evaluate_generator(valid_generator)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;validation soft dice loss: <span class="subst">&#123;val_loss:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;validation dice coefficient: <span class="subst">&#123;val_dice:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="expected-output-10">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">validation soft dice loss: <span class="number">0.4742</span></span><br><span class="line">validation dice coefficient: <span class="number">0.5152</span></span><br></pre></td></tr></table></figure>
<p><strong>NOTE:</strong> Do not run the code shown above on the Coursera platform as it will exceed the platform's memory limitations. However, you can run the code shown above locally on your machine or in Colab to practice measuring the overall performance on the validation set.</p>
<p>Like we mentioned above, due to memory limitiations on the Coursera platform we won't be runing the above code, however, you should take note of the <strong>expected output</strong> below it. We should note that due to the randomness in choosing sub-volumes, the values for soft dice loss and dice coefficient will be different each time that you run it.</p>
<p><a name="5-2"></a> ## 5.2 Patch-level predictions</p>
<p>When applying the model, we'll want to look at segmentations for individual scans (entire scans, not just the sub-volumes) - This will be a bit complicated because of our sub-volume approach. - First let's keep things simple and extract model predictions for sub-volumes. - We can use the sub-volume which we extracted at the beginning of the assignment.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">util.visualize_patch(X_norm[<span class="number">0</span>, :, :, :], y[<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<figure>
<img src="output_76_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<h4 id="add-a-batch-dimension">Add a 'batch' dimension</h4>
<p>We can extract predictions by calling <code>model.predict</code> on the patch. - We'll add an <code>images_per_batch</code> dimension, since the <code>predict</code> method is written to take in batches. - The dimensions of the input should be <code>(images_per_batch, num_channels, x_dim, y_dim, z_dim)</code>. - Use <a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.expand_dims.html">numpy.expand_dims</a> to add a new dimension as the zero-th dimension by setting axis=0</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_norm_with_batch_dimension = np.expand_dims(X_norm, axis=<span class="number">0</span>)</span><br><span class="line">patch_pred = model.predict(X_norm_with_batch_dimension)</span><br></pre></td></tr></table></figure>
<h4 id="convert-prediction-from-probability-into-a-category">Convert prediction from probability into a category</h4>
<p>Currently, each element of <code>patch_pred</code> is a number between 0.0 and 1.0. - Each number is the model's confidence that a voxel is part of a given class. - You will convert these to discrete 0 and 1 integers by using a threshold. - We'll use a threshold of 0.5. - In real applications, you would tune this to achieve your required level of sensitivity or specificity.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set threshold.</span></span><br><span class="line">threshold = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># use threshold to get hard predictions</span></span><br><span class="line">patch_pred[patch_pred &gt; threshold] = <span class="number">1.0</span></span><br><span class="line">patch_pred[patch_pred &lt;= threshold] = <span class="number">0.0</span></span><br></pre></td></tr></table></figure>
<p>Now let's visualize the original patch and ground truth alongside our thresholded predictions.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Patch and ground truth&quot;</span>)</span><br><span class="line">util.visualize_patch(X_norm[<span class="number">0</span>, :, :, :], y[<span class="number">2</span>])</span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Patch and prediction&quot;</span>)</span><br><span class="line">util.visualize_patch(X_norm[<span class="number">0</span>, :, :, :], patch_pred[<span class="number">0</span>, <span class="number">2</span>, :, :, :])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>Patch and ground truth</code></pre>
<figure>
<img src="output_82_1.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<pre><code>Patch and prediction</code></pre>
<figure>
<img src="output_82_3.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<h4 id="sensitivity-and-specificity">Sensitivity and Specificity</h4>
<p>The model is covering some of the relevant areas, but it's definitely not perfect. - To quantify its performance, we can use per-pixel sensitivity and specificity.</p>
<p>Recall that in terms of the true positives, true negatives, false positives, and false negatives,</p>
<p><span class="math display">\[\text{sensitivity} = \frac{\text{true positives}}{\text{true positives} + \text{false negatives}}\]</span></p>
<p><span class="math display">\[\text{specificity} = \frac{\text{true negatives}}{\text{true negatives} + \text{false positives}}\]</span></p>
<p>Below let's write a function to compute the sensitivity and specificity per output class.</p>
<details>
<summary>
<font size="3" color="darkgreen"><b>Hints</b></font>
</summary>
<p>
<ul>
<li>
Recall that a true positive occurs when the class prediction is equal to 1, and the class label is also equal to 1
</li>
<li>
Use <a target="_blank" rel="noopener" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html" > numpy.sum() </a>
</li>
</ul>
</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_class_sens_spec</span>(<span class="params">pred, label, class_num</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute sensitivity and specificity for a particular example</span></span><br><span class="line"><span class="string">    for a given class.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pred (np.array): binary arrary of predictions, shape is</span></span><br><span class="line"><span class="string">                         (num classes, height, width, depth).</span></span><br><span class="line"><span class="string">        label (np.array): binary array of labels, shape is</span></span><br><span class="line"><span class="string">                          (num classes, height, width, depth).</span></span><br><span class="line"><span class="string">        class_num (int): number between 0 - (num_classes -1) which says</span></span><br><span class="line"><span class="string">                         which prediction class to compute statistics</span></span><br><span class="line"><span class="string">                         for.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        sensitivity (float): precision for given class_num.</span></span><br><span class="line"><span class="string">        specificity (float): recall for given class_num</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># extract sub-array for specified class</span></span><br><span class="line">    class_pred = pred[class_num]</span><br><span class="line">    class_label = label[class_num]</span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE (REPLACE INSTANCES OF &#x27;None&#x27; with your code) ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute:</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># true positives</span></span><br><span class="line">    tp = np.<span class="built_in">sum</span>((class_label == <span class="number">1</span>) &amp; (class_pred == <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># true negatives</span></span><br><span class="line">    tn = np.<span class="built_in">sum</span>((class_label == <span class="number">0</span>) &amp; (class_pred == <span class="number">0</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#false positives</span></span><br><span class="line">    fp = np.<span class="built_in">sum</span>((class_label == <span class="number">0</span>) &amp; (class_pred == <span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># false negatives</span></span><br><span class="line">    fn = np.<span class="built_in">sum</span>((class_label == <span class="number">1</span>) &amp; (class_pred == <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute sensitivity and specificity</span></span><br><span class="line">    sensitivity = tp / (tp + fn)</span><br><span class="line">    specificity = tn / (tn + fp)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sensitivity, specificity</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TEST CASES</span></span><br><span class="line">pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">0.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Case #1&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">sensitivity, specificity = compute_class_sens_spec(pred, label, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;sensitivity: <span class="subst">&#123;sensitivity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;specificity: <span class="subst">&#123;specificity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #1
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 0.]]
sensitivity: 0.5000
specificity: 0.5000</code></pre>
<h4 id="expected-output-11">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#1</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span>]]</span><br><span class="line">sensitivity: <span class="number">0.5000</span></span><br><span class="line">specificity: <span class="number">0.5000</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Case #2&quot;</span>)</span><br><span class="line"></span><br><span class="line">pred = np.expand_dims(np.expand_dims(np.eye(<span class="number">2</span>), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">label = np.expand_dims(np.expand_dims(np.array([[<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0.0</span>, <span class="number">1.0</span>]]), <span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;pred:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(pred[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;label:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(label[<span class="number">0</span>, :, :, <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">sensitivity, specificity = compute_class_sens_spec(pred, label, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;sensitivity: <span class="subst">&#123;sensitivity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;specificity: <span class="subst">&#123;specificity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #2
pred:
[[1. 0.]
 [0. 1.]]
label:
[[1. 1.]
 [0. 1.]]
sensitivity: 0.6667
specificity: 1.0000</code></pre>
<h4 id="expected-output-12">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Test Case <span class="comment">#2</span></span><br><span class="line">pred:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">label:</span><br><span class="line">[[<span class="number">1.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">sensitivity: <span class="number">0.6667</span></span><br><span class="line">specificity: <span class="number">1.0000</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Note: we must explicity import &#x27;display&#x27; in order for the autograder to compile the submitted code</span></span><br><span class="line"><span class="comment"># Even though we could use this function without importing it, keep this import in order to allow the grader to work</span></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Case #3&quot;</span>)</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;y_test&#x27;</span>: [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],</span><br><span class="line">                   <span class="string">&#x27;preds_test&#x27;</span>: [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                   <span class="string">&#x27;category&#x27;</span>: [<span class="string">&#x27;TP&#x27;</span>,<span class="string">&#x27;TP&#x27;</span>,<span class="string">&#x27;TN&#x27;</span>,<span class="string">&#x27;TN&#x27;</span>,<span class="string">&#x27;TN&#x27;</span>,<span class="string">&#x27;FP&#x27;</span>,<span class="string">&#x27;FP&#x27;</span>,<span class="string">&#x27;FP&#x27;</span>,<span class="string">&#x27;FP&#x27;</span>,<span class="string">&#x27;FN&#x27;</span>,<span class="string">&#x27;FN&#x27;</span>,<span class="string">&#x27;FN&#x27;</span>,<span class="string">&#x27;FN&#x27;</span>,<span class="string">&#x27;FN&#x27;</span>]</span><br><span class="line">                  &#125;)</span><br><span class="line"></span><br><span class="line">display(df)</span><br><span class="line">pred = np.array( [df[<span class="string">&#x27;preds_test&#x27;</span>]])</span><br><span class="line">label = np.array( [df[<span class="string">&#x27;y_test&#x27;</span>]])</span><br><span class="line"></span><br><span class="line">sensitivity, specificity = compute_class_sens_spec(pred, label, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;sensitivity: <span class="subst">&#123;sensitivity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;specificity: <span class="subst">&#123;specificity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Test Case #3</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th>
</th>
<th>
y_test
</th>
<th>
preds_test
</th>
<th>
category
</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0
</th>
<td>
1
</td>
<td>
1
</td>
<td>
TP
</td>
</tr>
<tr>
<th>
1
</th>
<td>
1
</td>
<td>
1
</td>
<td>
TP
</td>
</tr>
<tr>
<th>
2
</th>
<td>
0
</td>
<td>
0
</td>
<td>
TN
</td>
</tr>
<tr>
<th>
3
</th>
<td>
0
</td>
<td>
0
</td>
<td>
TN
</td>
</tr>
<tr>
<th>
4
</th>
<td>
0
</td>
<td>
0
</td>
<td>
TN
</td>
</tr>
<tr>
<th>
5
</th>
<td>
0
</td>
<td>
1
</td>
<td>
FP
</td>
</tr>
<tr>
<th>
6
</th>
<td>
0
</td>
<td>
1
</td>
<td>
FP
</td>
</tr>
<tr>
<th>
7
</th>
<td>
0
</td>
<td>
1
</td>
<td>
FP
</td>
</tr>
<tr>
<th>
8
</th>
<td>
0
</td>
<td>
1
</td>
<td>
FP
</td>
</tr>
<tr>
<th>
9
</th>
<td>
1
</td>
<td>
0
</td>
<td>
FN
</td>
</tr>
<tr>
<th>
10
</th>
<td>
1
</td>
<td>
0
</td>
<td>
FN
</td>
</tr>
<tr>
<th>
11
</th>
<td>
1
</td>
<td>
0
</td>
<td>
FN
</td>
</tr>
<tr>
<th>
12
</th>
<td>
1
</td>
<td>
0
</td>
<td>
FN
</td>
</tr>
<tr>
<th>
13
</th>
<td>
1
</td>
<td>
0
</td>
<td>
FN
</td>
</tr>
</tbody>
</table>
</div>
<pre><code>sensitivity: 0.2857
specificity: 0.4286</code></pre>
<h4 id="expected-output-13">Expected Output</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Test case <span class="comment">#3</span></span><br><span class="line">...</span><br><span class="line">sensitivity: <span class="number">0.2857</span></span><br><span class="line">specificity: <span class="number">0.4286</span></span><br></pre></td></tr></table></figure>
<h4 id="sensitivity-and-specificity-for-the-patch-prediction">Sensitivity and Specificity for the patch prediction</h4>
<p>Next let's compute the sensitivity and specificity on that patch for expanding tumors.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sensitivity, specificity = compute_class_sens_spec(patch_pred[<span class="number">0</span>], y, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Sensitivity: <span class="subst">&#123;sensitivity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Specificity: <span class="subst">&#123;specificity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Sensitivity: 0.8049
Specificity: 0.9924</code></pre>
<h4 id="expected-output-14">Expected output:</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Sensitivity: <span class="number">0.7891</span></span><br><span class="line">Specificity: <span class="number">0.9960</span></span><br></pre></td></tr></table></figure>
<p>We can also display the sensitivity and specificity for each class.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_sens_spec_df</span>(<span class="params">pred, label</span>):</span></span><br><span class="line">    patch_metrics = pd.DataFrame(</span><br><span class="line">        columns = [<span class="string">&#x27;Edema&#x27;</span>, </span><br><span class="line">                   <span class="string">&#x27;Non-Enhancing Tumor&#x27;</span>, </span><br><span class="line">                   <span class="string">&#x27;Enhancing Tumor&#x27;</span>], </span><br><span class="line">        index = [<span class="string">&#x27;Sensitivity&#x27;</span>,</span><br><span class="line">                 <span class="string">&#x27;Specificity&#x27;</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i, class_name <span class="keyword">in</span> <span class="built_in">enumerate</span>(patch_metrics.columns):</span><br><span class="line">        sens, spec = compute_class_sens_spec(pred, label, i)</span><br><span class="line">        patch_metrics.loc[<span class="string">&#x27;Sensitivity&#x27;</span>, class_name] = <span class="built_in">round</span>(sens,<span class="number">4</span>)</span><br><span class="line">        patch_metrics.loc[<span class="string">&#x27;Specificity&#x27;</span>, class_name] = <span class="built_in">round</span>(spec,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> patch_metrics</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = get_sens_spec_df(patch_pred[<span class="number">0</span>], y)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure>
<pre><code>              Edema Non-Enhancing Tumor Enhancing Tumor
Sensitivity  0.8746              0.9419          0.8049
Specificity    0.97              0.9957          0.9924</code></pre>
<h4 id="expected-output-15">Expected output</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">              Edema Non-Enhancing Tumor Enhancing Tumor</span><br><span class="line">Sensitivity  <span class="number">0.9085</span>              <span class="number">0.9505</span>          <span class="number">0.7891</span></span><br><span class="line">Specificity  <span class="number">0.9848</span>              <span class="number">0.9961</span>           <span class="number">0.996</span></span><br></pre></td></tr></table></figure>
<p><a name="5-3"></a> ## 5.3 Running on entire scans As of now, our model just runs on patches, but what we really want to see is our model's result on a whole MRI scan.</p>
<ul>
<li>To do this, generate patches for the scan.</li>
<li>Then we run the model on the patches.</li>
<li>Then combine the results together to get a fully labeled MR image.</li>
</ul>
<p>The output of our model will be a 4D array with 3 probability values for each voxel in our data. - We then can use a threshold (which you can find by a calibration process) to decide whether or not to report a label for each voxel.</p>
<p>We have written a function that stitches the patches together: <code>predict_and_viz(image, label, model, threshold)</code> - Inputs: an image, label and model. - Ouputs: the model prediction over the whole image, and a visual of the ground truth and prediction.</p>
<p>Run the following cell to see this function in action!</p>
<h4 id="note-the-prediction-takes-some-time">Note: the prediction takes some time!</h4>
<ul>
<li>The first prediction will take about 7 to 8 minutes to run.</li>
<li>You can skip running this first prediction to save time.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># uncomment this code to run it</span></span><br><span class="line"><span class="comment"># image, label = load_case(DATA_DIR + &quot;imagesTr/BRATS_001.nii.gz&quot;, DATA_DIR + &quot;labelsTr/BRATS_001.nii.gz&quot;)</span></span><br><span class="line"><span class="comment"># pred = util.predict_and_viz(image, label, model, .5, loc=(130, 130, 77))                </span></span><br></pre></td></tr></table></figure>
<p>Here's a second prediction. - Takes about 7 to 8 minutes to run</p>
<p>Please run this second prediction so that we can check the predictions.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.getsizeof(image) / <span class="number">1000</span>  / <span class="number">1000</span></span><br></pre></td></tr></table></figure>
<pre><code>285696144</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">image, label = load_case(DATA_DIR + <span class="string">&quot;imagesTr/BRATS_003.nii.gz&quot;</span>, DATA_DIR + <span class="string">&quot;labelsTr/BRATS_003.nii.gz&quot;</span>)</span><br><span class="line">pred = util.predict_and_viz(image, label, model, <span class="number">.5</span>, loc=(<span class="number">130</span>, <span class="number">130</span>, <span class="number">77</span>))                </span><br></pre></td></tr></table></figure>
<figure>
<img src="output_103_0.png" alt="png" /><figcaption aria-hidden="true">png</figcaption>
</figure>
<h4 id="check-how-well-the-predictions-do">Check how well the predictions do</h4>
<p>We can see some of the discrepancies between the model and the ground truth visually. - We can also use the functions we wrote previously to compute sensitivity and specificity for each class over the whole scan. - First we need to format the label and prediction to match our functions expect.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">whole_scan_label = keras.utils.to_categorical(label, num_classes = <span class="number">4</span>)</span><br><span class="line">whole_scan_pred = pred</span><br><span class="line"></span><br><span class="line"><span class="comment"># move axis to match shape expected in functions</span></span><br><span class="line">whole_scan_label = np.moveaxis(whole_scan_label, <span class="number">3</span> ,<span class="number">0</span>)[<span class="number">1</span>:<span class="number">4</span>]</span><br><span class="line">whole_scan_pred = np.moveaxis(whole_scan_pred, <span class="number">3</span>, <span class="number">0</span>)[<span class="number">1</span>:<span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<p>Now we can compute sensitivity and specificity for each class just like before.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">whole_scan_df = get_sens_spec_df(whole_scan_pred, whole_scan_label)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(whole_scan_df)</span><br></pre></td></tr></table></figure>
<pre><code>              Edema Non-Enhancing Tumor Enhancing Tumor
Sensitivity   0.902              0.2617          0.8496
Specificity  0.9894              0.9998          0.9982</code></pre>
<h1 id="thats-all-for-now">That's all for now!</h1>
<p>Congratulations on finishing this challenging assignment! You now know all the basics for building a neural auto-segmentation model for MRI images. We hope that you end up using these skills on interesting and challenging problems that you face in the real world.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Medicine/" rel="tag"># Medicine</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/TensorFlow-js-Converter/2020/04/17/" rel="prev" title="TensorFlow.js Converter">
      <i class="fa fa-chevron-left"></i> TensorFlow.js Converter
    </a></div>
      <div class="post-nav-item">
    <a href="/Build-and-Evaluate-a-Linear-Risk-model/2020/04/18/" rel="next" title="Build and Evaluate a Linear Risk model">
      Build and Evaluate a Linear Risk model <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#brain-tumor-auto-segmentation-for-magnetic-resonance-imaging-mri"><span class="nav-number">1.</span> <span class="nav-text">Brain Tumor Auto-Segmentation for Magnetic Resonance Imaging (MRI)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#outline"><span class="nav-number">1.1.</span> <span class="nav-text">Outline</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#packages"><span class="nav-number">1.2.</span> <span class="nav-text">Packages</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#import-packages"><span class="nav-number">1.3.</span> <span class="nav-text">Import Packages</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mri-data-processing"><span class="nav-number">1.4.</span> <span class="nav-text">1.2 MRI Data Processing</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#generate-sub-volumes"><span class="nav-number">1.4.0.0.1.</span> <span class="nav-text">Generate sub-volumes</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#standardization-mean-0-stdev-1"><span class="nav-number">1.4.0.0.2.</span> <span class="nav-text">Standardization (mean 0, stdev 1)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#test-case"><span class="nav-number">1.4.1.</span> <span class="nav-text">Test Case:</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#test-extracting-2-2-2-sub-volume"><span class="nav-number">1.4.1.1.</span> <span class="nav-text">Test: Extracting (2, 2, 2) sub-volume</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output"><span class="nav-number">1.4.1.2.</span> <span class="nav-text">Expected output:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-1"><span class="nav-number">1.4.1.3.</span> <span class="nav-text">Expected output:</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#expected-output-2"><span class="nav-number">1.4.1.3.1.</span> <span class="nav-text">Expected output</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dice-coefficient-for-multiple-classes"><span class="nav-number">1.4.2.</span> <span class="nav-text">Dice Coefficient for Multiple classes</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-3"><span class="nav-number">1.4.2.1.</span> <span class="nav-text">Expected output:</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#multi-class-soft-dice-loss"><span class="nav-number">1.4.3.</span> <span class="nav-text">Multi-Class Soft Dice Loss</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#test-case-1"><span class="nav-number">1.4.3.1.</span> <span class="nav-text">Test Case 1</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-4"><span class="nav-number">1.4.3.2.</span> <span class="nav-text">Expected output:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#test-case-2"><span class="nav-number">1.4.3.3.</span> <span class="nav-text">Test Case 2</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-5"><span class="nav-number">1.4.3.4.</span> <span class="nav-text">Expected output:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#test-case-3"><span class="nav-number">1.4.3.5.</span> <span class="nav-text">Test Case 3</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-6"><span class="nav-number">1.4.3.6.</span> <span class="nav-text">Expected output:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#test-case-4"><span class="nav-number">1.4.3.7.</span> <span class="nav-text">Test Case 4</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-7"><span class="nav-number">1.4.3.8.</span> <span class="nav-text">Expected output:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#test-case-5"><span class="nav-number">1.4.3.9.</span> <span class="nav-text">Test Case 5</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-8"><span class="nav-number">1.4.3.10.</span> <span class="nav-text">Expected output:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#test-case-6"><span class="nav-number">1.4.3.11.</span> <span class="nav-text">Test Case 6</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-9"><span class="nav-number">1.4.3.12.</span> <span class="nav-text">Expected Output</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#using-the-validation-set-for-testing"><span class="nav-number">1.4.3.13.</span> <span class="nav-text">Using the validation set for testing</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-10"><span class="nav-number">1.4.3.14.</span> <span class="nav-text">Expected output:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#add-a-batch-dimension"><span class="nav-number">1.4.3.15.</span> <span class="nav-text">Add a &#39;batch&#39; dimension</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#convert-prediction-from-probability-into-a-category"><span class="nav-number">1.4.3.16.</span> <span class="nav-text">Convert prediction from probability into a category</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sensitivity-and-specificity"><span class="nav-number">1.4.3.17.</span> <span class="nav-text">Sensitivity and Specificity</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-11"><span class="nav-number">1.4.3.18.</span> <span class="nav-text">Expected output:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-12"><span class="nav-number">1.4.3.19.</span> <span class="nav-text">Expected output:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-13"><span class="nav-number">1.4.3.20.</span> <span class="nav-text">Expected Output</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sensitivity-and-specificity-for-the-patch-prediction"><span class="nav-number">1.4.3.21.</span> <span class="nav-text">Sensitivity and Specificity for the patch prediction</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-14"><span class="nav-number">1.4.3.22.</span> <span class="nav-text">Expected output:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#expected-output-15"><span class="nav-number">1.4.3.23.</span> <span class="nav-text">Expected output</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#note-the-prediction-takes-some-time"><span class="nav-number">1.4.3.24.</span> <span class="nav-text">Note: the prediction takes some time!</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#check-how-well-the-predictions-do"><span class="nav-number">1.4.3.25.</span> <span class="nav-text">Check how well the predictions do</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#thats-all-for-now"><span class="nav-number">2.</span> <span class="nav-text">That&#39;s all for now!</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ruochi Zhang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">268</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">46</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zhangruochi" title="GitHub  https:&#x2F;&#x2F;github.com&#x2F;zhangruochi" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zrc720@gmail.com" title="E-Mail  mailto:zrc720@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.healthinformaticslab.org/" title="http:&#x2F;&#x2F;www.healthinformaticslab.org" rel="noopener" target="_blank">HILab</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.shihaizhou.com/" title="http:&#x2F;&#x2F;www.shihaizhou.com" rel="noopener" target="_blank">Rose</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.csdn.net/cherish_CX/" title="https:&#x2F;&#x2F;blog.csdn.net&#x2F;cherish_CX&#x2F;" rel="noopener" target="_blank">Chunxia</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019  
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ruochi Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'qW3MLcAgcX96sB6qbegeL7rP-gzGzoHsz',
      appKey     : 'GL6JvT9DgGxqYrY5Vj6bXVuv',
      placeholder: "Thank you for your reply",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'en' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
